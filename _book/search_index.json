[["index.html", "PSYC234 (Weeks 15-19) 1 Introduction", " PSYC234 (Weeks 15-19) Amy Atkinson 2022-05-16 1 Introduction This is a collection of tuition material written for 2nd year Psychology undergraduates at Lancaster University (PSYC234, Weeks 15-19). It covers: the binomial test, non-parametric tests, binary logistic regression, and proportional odds models. It contains links to lecture materials, pre-lab activities, lab materials, and independent learning activities. It assumes that students are now able to use the RStudio server well. As such, there is little coverage of more basic concepts (e.g. how to uplaod data to the RStudio server). "],["binomial_test.html", "2 Lecture 5 (Binomial Test) 2.1 Lecture 2.2 Pre-lab work 2.3 Lab 2.4 Independent learning", " 2 Lecture 5 (Binomial Test) 2.1 Lecture Only one part of this lecture covers the binomial test. The other part covers factor analysis with Emma Mills. The lecture recording is available here. The slides are available here. 2.2 Pre-lab work There is no lab associated with this content. 2.3 Lab There is no lab associated with this content. 2.4 Independent learning This is optional, but recommended. The answers are found below. 2.4.1 Activity 1 One sample-test or binomial test? Disclaimer: All data are made up (and these estimates may be utterly ridiculous!) The answers are in the next section. For the following examples, write down whether you think the test conducted should be a one-sample t-test or a binomial test. You are the coach of a football team. You are interested in whether the running distance of your players significantly differs from the England national football team. You know, on average, England football players run 10km per game. You are the coach of a football team. You are interested in whether the proportion of games your team scores a goal is significantly different from that of the England national team. You know that on average, the England national team scores a goal in 60% of games. You are a university lecturer. You decide to introduce post-lecture worksheets to help students to consolidate knowledge learned during lectures. You are interested in whether the proportion of students passing the class test differs between this year and last year. You don’t have individual marks for last year’s students, but you do know that 74% of the last year’s cohort passed the class test. You are a university lecturer. You decide to introduce post-lecture worksheets to help students to consolidate knowledge learned during lectures. You are interested in whether the score on the class test differs between this year and last year. You know that last year, the average mark on the class test was 62% (or 0.62 expressed a proportion). You are a neonatal doctor (a doctor who specialising in caring for newborn babies). You think that babies born in your hospital are quite small. You are interested in whether the proportion of babies who are classed as “small for gestational age” differs between your hospital and the UK average (10%). You are a neonatal doctor (a doctor who specialising in caring for newborn babies). You think that babies that are born in your hospital are quite small. You are interested in whether the average weight of babies born at your hospital is significantly less than the UK average (3350g). 2.4.2 Activity 2 Identifying “success” You are a lecturer interested in whether the proportion of students passing your module differs from your colleague’s module. 82% of students (or 0.82 expressed as a proportion) pass your colleague’s module. You are the headteacher of a grammar school which has an entrance exam. You are interested in whether the proportion of children failing the test differs significantly from last year. The failure rate last year was 24% (or 0.24 expressed as a proportion). You are a teacher. You are interested in whether the proportion of students in your class with special educational needs and disabilities (SEND) significantly differs from the year group average (27%, or 0.27 expressed as a proportion). You have developed a new flu vaccine. You are interested in whether the proportion of people who develop side effects after your vaccine differs from the flu vaccine currently used by the NHS (37%, or 0.37 expressed as a proportion). 2.4.3 Activity 1: Answers One-sample t-test. The value for each individual is continuous.You are interested in whether the mean number of km runs differs from a known value. Binomial test. Two possible outcomes: team scores or team does not score). You are interested in whether the proportion that a given outcome occurs (i.e. your team scores a goal) differs from a known value. Binomial test. Two possible outcomes: Each student’s outcome is either “passed class test” or “failed class test”. You are interested in whether the proportion that a given outcome occurs (i.e. passes the class test) differs from a known value. One-sample t-test. The value for each individual is continuous. You are interested in whether the mean score students get differs from a known value. Binomial test. Two possible outcomes: Each baby’s outcome is either “small for gestational age” or “not small for gestational age”. You are interested in whether the proportion that a given outcome occurs (i.e. small for gestational age) differs from a known value. One-sample t-test. The value for each individual is continuous. You are interested in whether the mean weight of babies at your hospital differs from a known value. Take-home message: A one sample t-test is used when you are interested in comparing the mean of a sample to a known value. The binomial test is used when you are interested in comparing a sample’s proportion of “successes” to a known value. 2.4.4 Activity 2: Answers Success: pass the module. Failure: fail the module. Success: failing the test. Failure: passing the test. Success: Has special educational needs. Failure: Does not have special educational needs. Success: Has side effects. Failure: Does not have side effects. Take home message: Success refers to the outcome you are interested in. Sometimes this might be counterintuitive to how we typically think about ‘success’. "],["wilcoxon-rank-sum-signed-rank.html", "3 Lecture 6 (Non-parametric tests: Wilcoxon rank-sum and Wilcoxon signed-rank tests) 3.1 Lecture 3.2 Pre-lab work 3.3 Lab 3.4 Independent learning", " 3 Lecture 6 (Non-parametric tests: Wilcoxon rank-sum and Wilcoxon signed-rank tests) 3.1 Lecture This lecture comprises four parts: Part 1: An introduction to non-parametric tests Part 1 covers an introduction to non-parametric tests and when they might be useful to consider. The lecture recording is available here and the slides are available here. Part 2: Testing the assumption of normality with two independent groups Part 2 covers how to test the assumption of normality with two independent groups. The lecture recording is available here and the slides are available here. Part 3: The Wilcoxon-rank sum test Part 3 introduces you to the Wilcoxon rank-sum test. This includes when to use this test, the theory behind it, how the test statistic would be calculated manually, how to run the test in R, and how to interpret the output. The lecture recording is available here and the slides are available here. Part 4: The Wilcoxon signed-rank test Part 4 covers how to test the assumption of normality with two repeated measures and also introduces you to the Wilcoxon signed-rank test, including when to use the test, the theory behind it, how to calculate the test statistic manually, how to run the test in R and how to interpret the output. The lecture recording is available here and the slides are available here. 3.2 Pre-lab work Before the lab, please watch the following video. This walks you through how to perform a Wilcoxon rank-sum test and Wilcoxon signed-rank test in R. The R markdown script covered in this video and the required data files can be downloaded here. 3.3 Lab In the lab, we’ll practice running a Wilcoxon rank-sum and Wilcoxon signed-rank test in R. Please download the following zip file which contains two datasets: apple_study_data.csv and banana_study_data.csv. The datasets relate to the following research questions: 1. Apple dataset You are a researcher interested in whether the old saying “an apple a day keeps the doctor away is true”. You recruit 16 people and assign each participant to either a “0 apples” or “1 apple” condition. Participants in the “0 apple” condition eat 0 apples every day for a year. Participants in the “1 apple” condition eat 1 apple a day for a year. You ask participants to report how many times they visited the GP in the year. 2. Banana dataset You are interested in whether eating bananas keeps the doctor away. This time you recruit only one group of participants. In the first year, you ask them to eat 0 banana every day. In the second year, you ask them to eat 1 bananas a day. You ask them to report how many times they visit the GP in Year 1 and Year 2. Consider each research question, perform the normality checks, and then the appropriate analyses. 3.3.1 Model script Here is a model script that produces the answers to the above research questions. I use the word ‘model’ loosely, as you may have used different functions you’ve learned over the last two years (and that’s absolutely fine!). So don’t worry if you haven’t used the exact same functions as me. You should end up with the same results and interpretation at the end though. 3.3.2 Feedback on scripts Feedback on R scripts submitted by students is available here. 3.4 Independent learning This is optional, but recommended. The answers are found below. 3.4.1 Activity 1 Calculating test statistics manually 3.4.1.1 Wilcoxon rank-sum test You are a researcher interested in whether the number of cups of coffee drank affects how many admin tasks participants can get done in an hour. You assign to one of two conditions (drink 4 cups of coffee a day or drink 0 cups of coffee a day). After a week, you ask participants to come into the lab and ask them to complete a range of admin tasks. You count how many admin tasks they manage to complete. The data are below. Use this data to calculate the test statistic manually: Group Tasks_completed 4 cups 5 4 cups 18 4 cups 14 0 cups 6 0 cups 4 0 cups 17 0 cups 14 Steps: First rank the data Sum the ranks for each group Calculate the mean rank for each group Calculate the sum of ranks minus mean rank for each group What is the test statistic? What might R report as the test statistic and why? 3.4.1.2 Wilcoxon signed-rank test You are a researcher interested in whether a reading intervention helps children. You assess children’s reading skills and then give them all an intensive reading intervention. You then measure their reading abilities again. Use this data to calculate the test statistic manually Before_intervention After_intervention 23 27 34 34 67 91 65 67 21 44 Calculate the difference between “Before intervention” and “After intervention” Note whether the difference is positive or negative Rank the difference Next, add up positive ranks and negative ranks What is the test statistic (T)? R reports a test statistic “V” instead of R. What might V equal to? Why might V equal to two values? 3.4.2 Activity 2 Interpreting R output Interpret the following R output. Part 1 uses an independent groups design. Part 2 uses a repeated measures design. Please note, this data are different to that used in Activity 1 (so the test statistics will be different). 3.4.2.1 An independent groups design 3.4.2.1.1 Testing the assumption of normality 3.4.2.1.1.1 Group 1: ## ## Shapiro-Wilk normality test ## ## data: group1$Outcome ## W = 0.72773, p-value = 0.01196 3.4.2.1.1.2 Group 2: ## ## Shapiro-Wilk normality test ## ## data: group2$Outcome ## W = 0.95764, p-value = 0.8014 Is the assumption violated? 3.4.2.1.2 Interpret the descriptive statistics and the model output ## Warning in wilcox.test.default(x = DATA[[1L]], y = DATA[[2L]], ...): cannot compute exact p-value with ties ## ## Wilcoxon rank sum test with continuity correction ## ## data: Outcome by Group ## W = 19, p-value = 0.9357 ## alternative hypothesis: true location shift is not equal to 0 ## # A tibble: 2 × 5 ## Group med min max `n()` ## &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 1 17 1 35 6 ## 2 2 5.5 2 9 6 What can we conclude? Report in APA format. How was the p-value calculated? 3.4.2.2 A repeated measures design You are a researcher interested in whether the amount of chocolate eaten is different before and after the participant goes a diet. 3.4.2.2.1 Testing the assumption of normality ## ## Shapiro-Wilk normality test ## ## data: worksheet_activity2$Difference ## W = 0.76888, p-value = 0.01318 Is the assumption violated? 3.4.2.2.2 Interpret the descriptive statistics and the model output ## Warning in wilcox.test.default(worksheet_activity2$Before, worksheet_activity2$After, : cannot compute exact p-value with ## ties ## ## Wilcoxon signed rank test with continuity correction ## ## data: worksheet_activity2$Before and worksheet_activity2$After ## V = 36, p-value = 0.01368 ## alternative hypothesis: true location shift is not equal to 0 ## median_before median_after min_before min_after max_before max_after n() ## 1 232 18 230 4 235 33 8 What can we conclude? Report in APA format. How was the p-value calculated? 3.4.3 Activity 1: Answers 3.4.3.1 Wilcoxon rank-sum test Steps: 1. First rank the data Group Tasks_completed Rank 4 cups 5 2.0 4 cups 18 7.0 4 cups 14 4.5 0 cups 6 3.0 0 cups 4 1.0 0 cups 17 6.0 0 cups 14 4.5 2. Sum the ranks per group 4 cups = 13.5 0 cups = 14.5 3. Calculate the mean rank per group 4 cups = 3*4 = 12. 12/2 = 6 0 cups = 4*5 = 20. 20/2 = 10 4. Calculate the sum of ranks minus mean rank per group 4 cups = 13.5-6 = 7.5 0 cups = 14.5-10 = 4.5 5. What is the test statistic? Test statistic = The lowest sum of ranks. Test statistic = 4.5 6. What might R report as the test statistic and why? R reports the test statistic (W) as the sum of ranks minus the mean rank for the first factor level. R may therefore report the test statistic as 4.5 or 7.5. 3.4.3.2 Wilcoxon signed-rank test 1. Calculate the difference between “Before intervention” and “After intervention” Before_intervention After_intervention Difference 23 27 -4 34 34 Exclude 67 91 -24 65 67 -2 21 44 -23 2. Note whether the difference is positive or negative Before_intervention After_intervention Difference Sign 23 27 -4 Negative 34 34 Exclude 67 91 -24 Negative 65 67 -2 Negative 21 44 -23 Negative 3. Rank the difference Before_intervention After_intervention Difference Sign Rank 23 27 -4 Negative 2 34 34 Exclude 67 91 -24 Negative 4 65 67 -2 Negative 1 21 44 -23 Negative 3 4. Next, add up positive ranks and negative ranks Positive ranks: 0 Negative ranks: 10 5. What is the test statistic (T)? T = 0 6. R reports a test statistic “V” instead of R. What might V equal to? Why might V equal to two values? V = 0 or 10. V is equal to the sum of positive ranks. But whether ranks are positive or negative depends on whether you enter “before” or “after” first into the wilcox.test function (as this determines whether you calculate the difference by doing before-after or after-before). 3.4.4 Activity 2: Answers 3.4.4.1 An independent groups design: 3.4.4.2 Testing the assumption of normality 3.4.4.2.1 Group 1: ## ## Shapiro-Wilk normality test ## ## data: group1$Outcome ## W = 0.72773, p-value = 0.01196 3.4.4.2.2 Group 2: ## ## Shapiro-Wilk normality test ## ## data: group2$Outcome ## W = 0.95764, p-value = 0.8014 Is the assumption violated? Group 1: The assumption of normality is violated. Quite a few points deviate from the line in the Q-Q plot and the Shapiro-Wilk test is significant. Group 2: The assumption of normality is not violated. The dots generally follow the line well in the Q-Q plot and the Shapiro-Wilk test is non-significant. 3.4.4.3 Interpret the descriptive statistics and the model output ## Warning in wilcox.test.default(x = DATA[[1L]], y = DATA[[2L]], ...): cannot compute exact p-value with ties ## ## Wilcoxon rank sum test with continuity correction ## ## data: Outcome by Group ## W = 19, p-value = 0.9357 ## alternative hypothesis: true location shift is not equal to 0 ## # A tibble: 2 × 5 ## Group med min max `n()` ## &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 1 17 1 35 6 ## 2 2 5.5 2 9 6 What can we conclude? Report in APA format. The Wilcoxon rank-sum test revealed no significant difference between Group 1 (Median = 17, Range = 1-35) and Group 2 (Median = 5.5, Range = 2-9; W = 19, p = 0.936). Note: In practice, you should also calculate the effect size and report that. How was the p-value calculated? The normal approximation with the continuity correction 3.4.4.4 A repeated measures design 3.4.4.5 Testing the assumption of normality ## ## Shapiro-Wilk normality test ## ## data: worksheet_activity2$Difference ## W = 0.76888, p-value = 0.01318 Is the assumption violated? The assumption of normality is violated. Some points deviate quite a bit from the line in the Q-Q plot and the Shapiro-Wilk test is significant. 3.4.4.6 Interpret the descriptive statistics and the model output ## ## Wilcoxon signed rank test with continuity correction ## ## data: worksheet_activity2$Before and worksheet_activity2$After ## V = 36, p-value = 0.01368 ## alternative hypothesis: true location shift is not equal to 0 ## median_before median_after min_before min_after max_before max_after n() ## 1 232 18 230 4 235 33 8 What can we conclude? Report in APA format. The Wilcoxon signed-rank test revealed that participants ate significantly more grams of chocolate before the diet (Median = 232, Range = 230-235) than after the diet (Median = 18; Range = 4-33), V = 36, p = 0.014. Note: In practice, you should also calculate the effect size and report that. How was the p-value calculated? The normal approximation with the continuity correction "],["kruskal-friedman.html", "4 Lecture 7 (Non-parametric tests: Kruskal-Wallis test and Friedman’s ANOVA) 4.1 Lecture 4.2 Pre-lab work 4.3 Lab 4.4 Independent learning", " 4 Lecture 7 (Non-parametric tests: Kruskal-Wallis test and Friedman’s ANOVA) 4.1 Lecture This lecture comprises two parts: Part 1: Assessing normality with three or more independent groups and the Kruskal-Wallis test Part 1 covers how to assess the assumption of normality with three or more independent groups. It also covers the theory behind the Kruskal-Wallis test, how to calculate the Kruskal-Wallis test statistic manually, how to run the test in R, how to interpret the output, and how to conduct post-hoc comparisons. The lecture recording is available here and the slides are available here. Part 2: Assessing normality with three or more repeated measures and Friedman’s ANOVA Part 2 covers how to assess the assumption of normality with three or more repeated measures. It also covers Friedman’s ANOVA, including: the theory behind the test, how to calculate the test statistic manually, how to run the test in R and how to interpret output, and how to conduct post-hoc comparisons. The lecture recording is available here and the slides are available here. 4.2 Pre-lab work Before the lab, please watch the following video. This walks you through how to perform Friedman’s ANOVA in R.Please also take a look at this R markdown file. This covers how to run a Kruskal-Wallis test and Friedman’s ANOVA in R. 4.3 Lab In the lab, we’ll practice running a Kruskal-Wallis test and Friedman’s ANOVA in R. Please download the following zip file which contains two datasets: course_data_set.csv and memory_data.csv. The datasets relate to the following research questions: 1. Course dataset You are a psychology lecturer. You hear that the library is offering three statistics courses. You are interested in whether students who attend the courses perform significantly differently from each other. You recruit 18 people and assign each one to a course. After the courses are finished, you ask them to write an R script. You time how long it takes students to complete the task. You are interested in whether there is a significant effect of course on the time taken to complete the task. 2. Memory dataset You are a developmental psychologist. You are interested in whether working memory develops between 15 and 17 years of age. You recruit a sample of adolescents and test them on a working memory task when they are 15 years of age, 16 years of age, and 17 years of age. You then examine whether there is a significant effect of age on working memory score. 4.3.1 Model script Here is a model script that produces the answers to the above research questions. I use the word ‘model’ loosely, as you may have used different functions you’ve learned over the last two years (and that’s absolutely fine!). So don’t worry if you haven’t used the exact same functions as me. You should end up with the same results and interpretation at the end though. 4.3.2 Feedback on scripts Feedback on R scripts submitted by students is available here. 4.4 Independent learning This is optional, but recommended. The answers are found below. 4.4.1 Activity 1 Understanding how the non-parametric tests differ and when to use them It is really important that you understand which statistical test you should run in different situations. This activity will test your knowledge of the statistical tests you learned during this lecture and {#wilcoxon-rank-sum-signed-rank}. In each of the following scenario, you are interested in whether the type of chocolate eaten affects feelings of contentment (response = 0-100). For each scenario, think about the following questions: Scenario 1: You recruit 20 participants. On day 1, they eat milk chocolate. On day 2, they eat dark chocolate. On day 3, they eat white chocolate. How would you check whether the assumption of normality is violated for this design? If the assumption of normality is violated, which non-parametric test would you run? Scenario 2: You recruit 12 participants and randomly assign them to either a “white chocolate”, “milk chocolate”, or “dark chocolate” group. How would you check whether the assumption of normality is violated for this design? If the assumption of normality is violated, which non-parametric test would you run? Scenario 3: You recruit 7 participants. On day 1, they eat milk chocolate and on day 2, they eat dark chocolate. How would you check whether the assumption of normality is violated for this design? If the assumption of normality is violated, which non-parametric test would you run? Scenario 4: You recruit 10 participants and randomly assign them to either a “white chocolate” or “milk chocolate” group. How would you check whether the assumption of normality is violated for this design? If the assumption of normality is violated, which non-parametric test would you run? 4.4.2 Activity 2 Interpreting R output Interpret the following R output. Part 1 uses an independent groups design, whilst part 2 uses a repeated measures design. 4.4.2.1 Part 1: An independent groups design You are a developmental researcher interested in whether the books children are exposed to affects their language production (how many words they can say). You recruit 21 2-year-old children and assign them to one of three groups – “Pinocchio”, “Cinderella”, and “Gruffalo”. The children’s parents then read this story every day for three months (i.e. children in the “Gruffalo” group read the Gruffalo every day). You then ask their parents to complete a language production assessment on their child (score = 0-100). 4.4.2.1.1 Testing the assumption of normality: 4.4.2.1.1.1 Group 1: ## ## Shapiro-Wilk normality test ## ## data: Pinocchio$Words ## W = 0.75208, p-value = 0.01334 4.4.2.1.1.2 Group 2: ## ## Shapiro-Wilk normality test ## ## data: Cinderella$Words ## W = 0.96705, p-value = 0.8764 4.4.2.1.1.3 Group 3: ## ## Shapiro-Wilk normality test ## ## data: Gruffalo$Words ## W = 0.89119, p-value = 0.2809 Is the assumption violated? 4.4.2.1.2 Interpret the descriptive statistics and the model output ## # A tibble: 3 × 4 ## Book med_words min_words max_words ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 Cinderella 16 12 18 ## 2 Gruffalo 67 61 69 ## 3 Pinocchio 25 21 58 ## ## Kruskal-Wallis rank sum test ## ## data: Words by Book ## Kruskal-Wallis chi-squared = 17.853, df = 2, p-value = 0.0001328 ## Warning: Book was coerced to a factor. ## Dunn (1964) Kruskal-Wallis multiple comparison ## p-values adjusted with the Holm method. ## Comparison Z P.unadj P.adj ## 1 Cinderella - Gruffalo -4.225276 0.00002386477 0.00007159432 ## 2 Cinderella - Pinocchio -2.112638 0.03463174827 0.06926349653 ## 3 Gruffalo - Pinocchio 2.112638 0.03463174827 0.03463174827 What can we conclude? Report in APA format. 4.4.2.2 Part 2: A repeated measures design You are a researcher interested in whether the number of hours sleep individuals get affects their performance on an attention task (score = 0-100). You recruit nine participants, with all participants taking part in three conditions. In the first condition, participants get 6 hours sleep the night before (6 hours). In the second condition, they get 8 hours sleep the night before (8 hours), and in the third condition, they get 10 hours sleep the night before (10 hours). 4.4.2.2.1 Testing the assumption of normality: 6 hours condition: ## ## Shapiro-Wilk normality test ## ## data: sleep_data$six_hours ## W = 0.7785, p-value = 0.01157 8 hours condition: ## ## Shapiro-Wilk normality test ## ## data: sleep_data$eight_hours ## W = 0.90246, p-value = 0.2666 10 hours condition: ## ## Shapiro-Wilk normality test ## ## data: sleep_data$ten_hours ## W = 0.96963, p-value = 0.8915 Is the assumption violated? 4.4.2.2.2 Interpret the descriptive statistics and the model output ## Participant Condition Score ## 1 1 six_hours 46 ## 2 2 six_hours 47 ## 3 3 six_hours 49 ## 4 4 six_hours 54 ## 5 5 six_hours 89 ## 6 6 six_hours 86 ## 7 7 six_hours 84 ## 8 8 six_hours 81 ## 9 9 six_hours 49 ## 10 1 eight_hours 66 ## 11 2 eight_hours 68 ## 12 3 eight_hours 69 ## 13 4 eight_hours 73 ## 14 5 eight_hours 76 ## 15 6 eight_hours 78 ## 16 7 eight_hours 67 ## 17 8 eight_hours 80 ## 18 9 eight_hours 81 ## 19 1 ten_hours 96 ## 20 2 ten_hours 97 ## 21 3 ten_hours 95 ## 22 4 ten_hours 96 ## 23 5 ten_hours 94 ## 24 6 ten_hours 92 ## 25 7 ten_hours 91 ## 26 8 ten_hours 95 ## 27 9 ten_hours 99 ## ## Friedman rank sum test ## ## data: as.matrix(sleep_data_reduced) ## Friedman chi-squared = 13.556, df = 2, p-value = 0.001139 ## ## Pairwise comparisons using Conover&#39;s all-pairs test for a two-way balanced complete block design ## data: y, groups and blocks ## eight_hours six_hours ## six_hours 0.817 - ## ten_hours 0.015 0.014 ## ## P value adjustment method: holm ## med_six_hours med_eight_hours med_ten_hours min_six_hours min_eight_hours min_ten_hours max_six_hours max_eight_hours ## 1 54 73 95 46 66 91 89 81 ## max_ten_hours ## 1 99 What can we conclude? Report in APA format. 4.4.3 Activity 1: Answers Scenario 1: You recruit 20 participants. On day 1, they eat milk chocolate. On day 2, they eat dark chocolate. On day 3, they eat white chocolate. How would you check whether the assumption of normality is violated for this design? Assess whether the assumption of normality is violated per condition. This can be done using Q-Q plots and the Shapiro-Wilk test If the assumption of normality is violated, which non-parametric test would you run? Friedman’s ANOVA Scenario 2: You recruit 12 participants and randomly assign them to either a “white chocolate”, “milk chocolate”, or “dark chocolate” group. How would you check whether the assumption of normality is violated for this design? Assess whether the assumption of normality is violated per group. This can be done using Q-Q plots and the Shapiro-Wilk test. If the assumption of normality is violated, which non-parametric test would you run? Kruskal-Wallis test Scenario 3: You recruit 7 participants. On day 1, they eat milk chocolate and on day 2, they eat dark chocolate. How would you check whether the assumption of normality is violated for this design? Calculate a difference score for each participant (Timepoint 1 – Timepoint 2). Assess whether the assumption of normality is violated for the “difference”. This can be done using Q-Q plots and the Shapiro-Wilk test. If the assumption of normality is violated, which non-parametric test would you run? Wilcoxon signed-rank test Scenario 4: You recruit 10 participants and randomly assign them to either a “white chocolate” or “milk chocolate” group. How would you check whether the assumption of normality is violated for this design? Assess whether the assumption of normality is violated per group. This can be done using Q-Q plots and the Shapiro-Wilk test If the assumption of normality is violated, which non-parametric test would you run? Wilcoxon rank-sum test 4.4.4 Activity 2: Answers 4.4.4.1 Part 1: An independent groups design 4.4.4.1.1 Testing the assumption of normality: 4.4.4.1.1.1 Group 1: ## ## Shapiro-Wilk normality test ## ## data: Pinocchio$Words ## W = 0.75208, p-value = 0.01334 4.4.4.1.1.2 Group 2: ## ## Shapiro-Wilk normality test ## ## data: Cinderella$Words ## W = 0.96705, p-value = 0.8764 4.4.4.1.1.3 Group 3: ## ## Shapiro-Wilk normality test ## ## data: Gruffalo$Words ## W = 0.89119, p-value = 0.2809 Is the assumption violated? The Q-Q plot and the Shapiro-Wilk test suggests that the assumption of normality is violated for the Pinocchio group. Data in the Cinderella and Gruffalo group does not appear to violate the assumption. 4.4.4.1.2 Interpret the descriptive statistics and the model output ## # A tibble: 3 × 4 ## Book med_words min_words max_words ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 Cinderella 16 12 18 ## 2 Gruffalo 67 61 69 ## 3 Pinocchio 25 21 58 ## ## Kruskal-Wallis rank sum test ## ## data: Words by Book ## Kruskal-Wallis chi-squared = 17.853, df = 2, p-value = 0.0001328 ## Warning: Book was coerced to a factor. ## Dunn (1964) Kruskal-Wallis multiple comparison ## p-values adjusted with the Holm method. ## Comparison Z P.unadj P.adj ## 1 Cinderella - Gruffalo -4.225276 0.00002386477 0.00007159432 ## 2 Cinderella - Pinocchio -2.112638 0.03463174827 0.06926349653 ## 3 Gruffalo - Pinocchio 2.112638 0.03463174827 0.03463174827 What can we conclude? Report in APA format. The Kruskal-Wallis test revealed a significant effect of book on the language production score, H(2) = 17.85, p &lt; .001. Post-hoc comparisons were conducted using Dunn’s test, with p-values corrected using Bonferroni-Holm. There was a significant difference between the Cinderella (median = 16; range = 12-18) and the Gruffalo groups (median = 67; range = 61-69), with participants in the Gruffalo group achieving a significantly higher score (p &lt; .001). Participants in the Gruffalo group also achieved a significantly higher score than participants in the Pinocchio group (median = 25; range = 21-58; p = .035). No significant difference was observed between the Cinderella and the Pinocchio groups (p = .069). 4.4.4.2 Part 2: A repeated measures design 4.4.4.2.1 Testing the assumption of normality: 6 hours condition: ## ## Shapiro-Wilk normality test ## ## data: sleep_data$six_hours ## W = 0.7785, p-value = 0.01157 8 hours condition: ## ## Shapiro-Wilk normality test ## ## data: sleep_data$eight_hours ## W = 0.90246, p-value = 0.2666 10 hours condition: ## ## Shapiro-Wilk normality test ## ## data: sleep_data$ten_hours ## W = 0.96963, p-value = 0.8915 Is the assumption violated? Data in the 6 hour condition appears to violate the assumption of normality. 4.4.4.2.2 Interpret the descriptive statistics and the model output ## ## Friedman rank sum test ## ## data: as.matrix(sleep_data_reduced) ## Friedman chi-squared = 13.556, df = 2, p-value = 0.001139 ## ## Pairwise comparisons using Conover&#39;s all-pairs test for a two-way balanced complete block design ## data: y, groups and blocks ## eight_hours six_hours ## six_hours 0.817 - ## ten_hours 0.015 0.014 ## ## P value adjustment method: holm ## med_six_hours med_eight_hours med_ten_hours min_six_hours min_eight_hours min_ten_hours max_six_hours max_eight_hours ## 1 54 73 95 46 66 91 89 81 ## max_ten_hours ## 1 99 What can we conclude? Report in APA format. A Friedman’s ANOVA revealed a significantly effect of sleep hours on the attention score, \\(x^{2}_{F}\\)(2) = 13.56, p = .001. Post-hoc comparisons were then conducting using the Conover test, with p-values corrected using Bonferroni-Holm. A significant difference emerged between the 6 hour (median = 54; range = 46-89) and the 10 hour conditions (median = 95; range = 91-99; p =.014), with participants performing better in the 10 hour condition. There was also a significant difference between the 8 hour (median = 73; range = 66-81) and the 10 hour conditions (p = .015). No significant difference emerged between the 6 hour and 8 hour conditions (p = .817). "],["binary-log-regression.html", "5 Lecture 8 (Binary logistic regression) 5.1 Lecture 5.2 Pre-lab work 5.3 Lab 5.4 Independent learning", " 5 Lecture 8 (Binary logistic regression) 5.1 Lecture This lecture comprises four parts: Part 1: Why do I need to worry about binary logistic regression? Part 1 covers why it is important to understand binary logistic regression, and why it is not appropriate to run a linear regression model when the outcome is continuous. It also covers an introduction to binary logistic regression. The lecture recording is available here and the slides are available here. Part 2: Odds and odds ratios Part 2 introduces the concept of odds and odds ratios, and provides an example of how to calculate odds ratios manually (to aid in understanding about what odds and odds ratios represents). The lecture recording is available here and the slides are available here. Part 3: Assumptions of binary logistic regression with one categorical predictor Part 3 covers the assumptions of binary logistic regression when you have one categorical predictor. The lecture recording is available here and the slides are available here. Part 4: Running a binary logistic regression model (with one categorical predictor) in R Part 4 covers how to run a binary logistic regression model with one categorical predictor in R, and how to interpret the output. The lecture recording is available here and the slides are available here. 5.2 Pre-lab work Before the lab, please watch the following video. This walks you through how to run a binary logistic regression model with one categorical predictor in R. The R markdown script covered in this video can be found here. 5.3 Lab In the lab, we’ll run a binary logistic regression model with one categorical predictor in R. Please download the following datafile: reptile_data.csv. Use one of the following templates to ensure the packages are loaded in correctly to avoid conflicts: R Markdown and R. The datasets relate to the following research question: You are interested in whether the country an individual lives (UK/Australia) predicts reptile ownership (Yes/No). In the dataset, the outcome variable (reptile) is coded as “Y” and “N” (where Y = Yes and N = No) To make sure we should all end up with the same output, set UK as your reference category for the “Country” variable. Work through the following steps: Prepare our data for analysis Explore our data Run the binary logistic regression model Evaluate the model Evaluate the individual predictors Predicted probabilities Interpret the output 5.3.1 Model script Here is a model script that produces the answers to the above research question. I use the word ‘model’ loosely, as you may have used different functions you’ve learned over the last two years (and that’s absolutely fine!). So don’t worry if you haven’t used the exact same functions as me. You should end up with the same results and interpretation at the end though. 5.3.2 Feedback on scripts Feedback on R scripts submitted by students is available here. 5.4 Independent learning This is optional, but recommended. The answers are found below. 5.4.1 Activity 1 Calculating odds ratios manually Activity 1 will involve work with the following data. You are a researcher interested in whether being excited (yes/no) predicts whether an individual passes their driving test (yes/no). Here is a table of frequencies. ## ## Excited - No Excited - Yes ## Passed - No 29 12 ## Passed - Yes 8 14 What are the odds of passing the driving test in the “Excited – Yes” group? What are the odds of passing the driving test in the “Excited – No” group? What is the odds ratio (where “Excited – No” is the original odds)? What does this odds ratio mean? Is there evidence of quasi-complete separation or complete separation here? Give a reason for your answer. 5.4.2 Activity 2 Interpreting R output Activity 2 examines the following research question. You are a researcher interested in whether being rich (yes/no) predicts whether an individual owns a Tesla. Here is a table of frequencies: ## ## Tesla - Yes Tesla - No ## Rich - No 34 3 ## Rich - Yes 5 5 You analyse this data in R and the output of your model is below. For the outcome, you set “0” as “Has a Tesla – No” and “1” as “Has a Tesla – Yes” 5.4.2.1 Model output Here is the model output: l8_w2$tesla_numeric &lt;- recode(l8_w2$Tesla, &quot;No&quot; = 0, &quot;Yes&quot;= 1) tesla_model &lt;- glm(tesla_numeric ~ Rich, data = l8_w2, family=binomial()) summary(tesla_model) ## ## Call: ## glm(formula = tesla_numeric ~ Rich, family = binomial(), data = l8_w2) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -1.1774 -0.4112 -0.4112 -0.4112 2.2416 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -2.4277 0.6023 -4.031 0.0000556 *** ## RichYes 2.4277 0.8734 2.780 0.00544 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 42.885 on 46 degrees of freedom ## Residual deviance: 34.687 on 45 degrees of freedom ## AIC: 38.687 ## ## Number of Fisher Scoring iterations: 5 5.4.2.2 Evaluating the model output You run some code to produce the model’s chi-square statistic, the degrees of freedom and the p-value. These are displayed below: Chi square = 8.2 Degrees of freedom = 1 P-value = 0.004 What do these values indicate? 5.4.2.3 Evaluating Pseudo R2 PseudoR2(tesla_model, which = &quot;all&quot;) ## McFadden McFaddenAdj CoxSnell Nagelkerke AldrichNelson VeallZimmermann Efron ## 0.1911699 0.0978972 0.1600663 0.2674640 0.1485248 0.3113013 0.2081168 ## McKelveyZavoina Tjur AIC BIC logLik logLik0 G2 ## 0.2308156 0.2081168 38.6866797 42.3869749 -17.3433399 -21.4425007 8.1983218 Which Pseudo R2 values might you report (based on the lecture)? What is the value of these Pseudo R2s? 5.4.2.4 Evaluating the individual predictors Looking back at the summary output, consider the following questions: What is the reference category for the predictor “Rich”? What does the Intercept Estimate represent? What does the RichYes Estimate represent? 5.4.2.4.1 Exponentiating the estimates: tesla_model_exponentiated &lt;- exp(tesla_model$coefficients) tesla_model_exponentiated ## (Intercept) RichYes ## 0.08823529 11.33333333 What does the Intercept represent? What does the RichYes value represent? Can you interpret the RichYes value? 5.4.2.4.2 Confidence intervals: tesla_model_odds_confidence_intervals &lt;- exp(confint(tesla_model)) ## Waiting for profiling to be done... tesla_model_odds_confidence_intervals ## 2.5 % 97.5 % ## (Intercept) 0.02124284 0.2452701 ## RichYes 2.15765202 71.8937055 What does the RichYes 95% confidence intervals represent? From the p-value in the summary table for the RichYes row, what can you conclude? Is there another output we could look at to reach the same broad conclusion (regarding whether the predictor significantly predicts the outcome)? 5.4.3 Activity 1: Answers Calculating odds ratios manually ## ## Excited - No Excited - Yes ## Passed - No 29 12 ## Passed - Yes 8 14 What are the odds of passing the driving test in the “Excited – Yes” group? The probability of individuals who are excited (Excited – Yes) passing the driving test: 14/26 = 0.5384615385 14 is the number of participants who were excited and passed the driving test. 26 is the total number of individuals who responded “Excited – Yes” (14+12) The probability of individuals who are excited (Excited – Yes) not passing the driving test: 12/26 = 0.4615384615 12 is the number of participants who were excited and did not pass the driving test. 26 is the total number of individuals who responded “Excited – Yes” (14+12) The odds of individuals who are excited passing the driving test: 0.5384615385 / 0.4615384615 = 1.1666666668 What are the odds of passing the driving test in the “Excited – No” group? The probability of individuals who are not excited (Excited – No) passing the driving test: 8/37 = 0.216216216 8 is the number of participants who were not excited and passed the driving test. 37 is the total number of individuals who responded “Excited – No” (8+29) The probability of individuals who are excited (Excited - No) not passing the driving test: 29/37 = 0.783783783 29 is the number of participants who were not excited and did not pass the driving test. 37 is the total number of individuals who responded “Excited – No” (8+29) The odds of individuals who are not excited passing the driving test: 0.216216216 / 0.783783783 = 0.275862069 What is the odds ratio (where “Excited – No” is the original odds)? 1.1666666668 / 0.275862069 = 4.23 The odds ratio = 4.23 What does this odds ratio mean? Individuals who were excited had a 4.23x higher odds of passing the driving test relative to individuals who were not excited. Is there evidence of quasi-complete separation or complete separation here? Give a reason for your answer. No – all cells have quite a few observations so there is no evidence of quasi-complete separation or complete separation. 5.4.4 Activity 2: Answers Activity 2 examines the following research question. You are a researcher interested in whether being rich (yes/no) predicts whether an individual owns a Tesla. Here is a table of frequencies: ## ## Tesla - Yes Tesla - No ## Rich - No 34 3 ## Rich - Yes 5 5 You analyse this data in R and the output of your model is below. For the outcome, you set “0” as “Has a Tesla – No” and “1” as “Has a Tesla – Yes” 5.4.4.1 Model output Here is the model output: l8_w2$tesla_numeric &lt;- recode(l8_w2$Tesla, &quot;No&quot; = 0, &quot;Yes&quot;= 1) tesla_model &lt;- glm(tesla_numeric ~ Rich, data = l8_w2, family=binomial()) summary(tesla_model) ## ## Call: ## glm(formula = tesla_numeric ~ Rich, family = binomial(), data = l8_w2) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -1.1774 -0.4112 -0.4112 -0.4112 2.2416 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -2.4277 0.6023 -4.031 0.0000556 *** ## RichYes 2.4277 0.8734 2.780 0.00544 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 42.885 on 46 degrees of freedom ## Residual deviance: 34.687 on 45 degrees of freedom ## AIC: 38.687 ## ## Number of Fisher Scoring iterations: 5 5.4.4.2 Evaluating the model output You run some code to produce the model’s chi-square statistic, the degrees of freedom and the p-value. These are displayed below: Chi square = 8.2 Degrees of freedom = 1 P-value = 0.004 What do these values indicate? \\(x^{2}\\)(1) = 8.20, p = .004. This indicates that adding the “Rich” variable to our model significantly improved the fit, compared to the null model containing intercept only 5.4.4.3 Evaluating Pseudo R2 PseudoR2(tesla_model, which = &quot;all&quot;) ## McFadden McFaddenAdj CoxSnell Nagelkerke AldrichNelson VeallZimmermann Efron ## 0.1911699 0.0978972 0.1600663 0.2674640 0.1485248 0.3113013 0.2081168 ## McKelveyZavoina Tjur AIC BIC logLik logLik0 G2 ## 0.2308156 0.2081168 38.6866797 42.3869749 -17.3433399 -21.4425007 8.1983218 Which Pseudo R2 values might you report (based on the lecture)? McFadden, CoxSnell and Nagelkerke What is the value of these Pseudo R2s? McFadden = 0.19 CoxSnell = 0.16 Nagelkerke = 0.27 5.4.4.4 Evaluating the individual predictors Looking back at the summary output, consider the following questions: What is the reference category for the predictor “Rich”? “No” is our reference category for the Rich variable What does the Intercept Estimate represent? The log odds of someone with a Rich value of “No” having a tesla What does the RichYes Estimate represent? The change in the log odds of having a tesla value of “Yes” when going from the reference category (RichNo) to RichYes 5.4.4.4.1 Exponentiating the estimates: tesla_model_exponentiated &lt;- exp(tesla_model$coefficients) tesla_model_exponentiated ## (Intercept) RichYes ## 0.08823529 11.33333333 What does the Intercept represent? The odds of having a tesla for individuals who are not rich What does the RichYes value represent? The change in odds (i.e. the odds ratio) of having a tesla (i.e. tesla = yes) when going from RichNo to RichYes Can you interprert the RichYes value? The odds of having a tesla are 11.33x higher if you are rich than if you are not rich 5.4.4.4.2 Confidence intervals: tesla_model_odds_confidence_intervals &lt;- exp(confint(tesla_model)) ## Waiting for profiling to be done... tesla_model_odds_confidence_intervals ## 2.5 % 97.5 % ## (Intercept) 0.02124284 0.2452701 ## RichYes 2.15765202 71.8937055 What does the RichYes 95% confidence intervals represent? The 95% confidence around the odds ratio (for the comparison between RichNo to RichYes). From the p-value in the summary table for the RichYes row, what can you conclude? Whether an individual is rich (yes/no) significantly predicts whether they have a tesla (yes/no; p = .005) Is there another output we could look at to reach the same broad conclusion (regarding whether the predictor significantly predicts the outcome)? Yes, you could also look at the output for the 95% confidence interval around the odds ratio. As both the lower and upper bound of the confidence interval are above 1, this indicates that the p-value would be significant - whether an individual is rich (yes/no) significantly predicts whether they have a tesla (yes/no) "],["extending-binary-regression.html", "6 Lecture 9 (Extending binary logistic regression) 6.1 Lecture 6.2 Pre-lab work 6.3 Lab 6.4 Independent learning", " 6 Lecture 9 (Extending binary logistic regression) 6.1 Lecture This lecture extends the content taught in {#extending-binary-regression} to three new contexts: binary logistic regression with different types of predictors, multiple binary logistic regression, and proportional odds models. Part 1: Binary logistic regression with different types of predictors This part of the lecture covers binary logistic regression with one categorical predictor with three or more levels and binary logistic regression with one continuous predictor. The lecture recording is available here and the slides are available here. Part 2: Multiple binary logistic regression Part 2 covers multiple binary logistic regression: binary logistic regression with multiple predictor variables (i.e. more than one predictor). The lecture recording is available here and the slides are available here. Part 3: Proportional odds models Part 3 covers proportional odds models - a type of model that could be considered if the outcome is ordinal (has ordered levels). The lecture recording is available here and the slides are available here. 6.2 Pre-lab work Before the lab, please watch the following video. This walks you through how to run a proportional odds model. Please also take a look at this R Markdown file. This covers how to run a multiple binary logistic regression model and a proportional odds model 6.3 Lab In the lab, we’ll run a multiple binary logistic regression model and a proportional odds model. Please download the following zip file which contains two datasets: measles_data.csv and academic_data.csv. Use one of the following templates to ensure the packages are loaded in correctly to avoid conflicts: R Markdown and R. The datasets relate to the following research questions: 1. Academic dataset You are interested in factors that predict academic achievement in mathematics. Children’s academic achievement can be rated as below expected, at expected or above expected. The predictors you are interested in are: * Number if hours spent revising (continuous) * Likes school (Yes/no) * Favourite subject (Maths, English or Science) To make sure we should all end up with the same output: Set the reference category for Likes school as “No” Set the reference category for Favourite subject as “Maths” 2. Measles dataset You work in a nursery. In the nursery, there has been an outbreak of measles. You are interested in factors that predict whether a child in your nursery will have measles (yes/no). The predictors you are interested in are: * Number of hours spent at nursery weekly (continuous) * Has siblings(Yes/no) * Vaccinated against measles (Yes/no) For the categorical predictors: * Set the reference category for Siblings as “No” * Set the reference category for Vaccinated as “No” For the outcome (measles – yes/no): * Set No as 0, and Yes as 1 6.3.1 Model script Here is a model script that produces the answers to the above research questions. I use the word ‘model’ loosely, as you may have used different functions you’ve learned over the last two years (and that’s absolutely fine!). So don’t worry if you haven’t used the exact same functions as me. You should end up with the same results and interpretation at the end though. 6.3.2 Feedback on scripts Feedback on R scripts submitted by students is available here. 6.4 Independent learning This is optional, but recommended. The answers are found below. 6.4.1 Activity 1 Interpreting odds ratios from multiple binary logistic regression Imagine you are interested in examining factors that predict whether an individual has a dog (yes/no). The variables you are interested in are: has children (yes/no), working pattern (full-time, part-time, unemployed), and number of pets previously (continuous). You code dog into a numeric variable where 0 = No and 1 = Yes. You set “No” as the reference category for “has children” and “unemployed” as the reference category for working pattern. Below are the odds ratios and 95% confidence intervals around the odds ratio that you obtain. Odds ratio Lower confidence interval bound Upper confidence interval bound Has_childrenYes 3.67 2.14 5.64 Working_patternFull-time 6.85 1.34 14.67 Working_patternPart-time 3.12 0.67 1.35 Num_previous_pets 0.45 0.23 0.67 Can you interpert the odds ratios? Which rows would be significant if you looked at the p-values and why? 6.4.2 Activity 2 Interpreting odds ratios from a proportional odds model Imagine you are interested in examining factors that predict severity of a disease (mild, moderate or severe). The variables you are interested in are: pre-existing health condition (yes/no), smokes (yes/no), and number of units of alcohol consumed weekly (continuous). You code disease severity into an ordered factor (mild &lt; moderate &lt; severe). You set “No” as the reference category for “pre-existing health condition” and “smoking”. Below are the odds ratios and confidence intervals you obtain. Odds ratio Lower confidence interval bound Upper confidence interval bound Pre-existing_healthYes 2.31 1.45 4.56 SmokesYes 1.45 0.89 4.56 Num_alcohol_units 1.12 1.02 1.45 Can you interpret the odds ratios? Which rows would be significant if you looked at the p-values and why? 6.4.3 Activity 1: Answers Odds ratio Lower confidence interval bound Upper confidence interval bound Has_childrenYes 3.67 2.14 5.64 Working_patternFull-time 6.85 1.34 14.67 Working_patternPart-time 3.12 0.67 1.35 Num_previous_pets 0.45 0.23 0.67 Can you interpret the odds ratios? You could interpret the odds ratios in two ways: Way one: Individuals who had children had higher odds of having a dog relative to individuals who did not have children (odds ratio = 3.67, 95% confidence interval = 2.14-5.64) when holding other variables constant Individuals who worked full time had had higher odds of having a dog relative to individuals who were unemployed (odds ratio = 6.85, 95% confidence interval = 1.34-14.67) when holding other variables constant Individuals who worked part-time had higher odds of having a dog relative to individuals who were unemployed (odds ratio = 3.12, 95% confidence interval = 0.67-1.35) when holding other variables constant A one unit increase in the number of previous pets was associated with lower odds of currently having a dog (odds ratio = 0.45, 95% confidence interval = 0.23-0.67) when holding other variables constant Way two: Individuals who had children had 3.67x higher odds of having a dog relative to individuals who did not have children (95% confidence interval = 2.14-5.64), when holding other variables constant Individuals who worked full time had had 6.85x higher odds of having a dog relative to individuals who were unemployed (95% confidence interval = 1.34-14.67), when holding other variables constant Individuals who worked part-time had 3.12x higher odds of having a dog relative to individuals who were unemployed (95% confidence interval = 0.67-1.35) A one unit increase in the number of previous pets was associated with a 0.45x higher odds (i.e. lower odds) of having a dog (odds ratio = 0.45, 95% confidence interval = 0.23-0.67), when holding other variables constant Which rows would be significant if you looked at the p-values and why? * Has_childrenYes * Working_patternFull-time * Num_previous_pets The 95% confidence interval around the odds ratio does not cross 1 for these comparisons (i.e. both the upper and the lower bound are higher than 1 OR both the upper and the lower bound are lower than 1). For Working_patternPart-time, the 95% confidence interval crosses 1 (i.e. the lower confidence interval bound is below 1 and the higher confidence interval bound is above 1). This means when we look at the output, the p-value for Working_patternPart-time will be above 0.05 (i.e. not significant). 6.4.4 Activity 2: Answers Odds ratio Lower confidence interval bound Upper confidence interval bound Pre-existing_healthYes 2.31 1.45 4.56 SmokesYes 1.45 0.89 4.56 Num_alcohol_units 1.12 1.02 1.45 Can you interpret the odds ratios? You can interpret the odds ratios in two ways: Way one: Individuals who had a pre-existing health condition had higher odds of having more severe disease (e.g. “severe” disease vs “mild” or “moderate” disease) relative to individuals who did not have a pre-existing health condition (odds ratio = 2.31, 95% confidence interval = 1.45-4.56), when holding other variables constant Individuals who smoked had higher odds of having more severe disease (e.g. “severe” disease vs “mild” or “moderate” disease) relative to individuals who did not smoke (odds ratio = 1.45, 95% confidence interval = 0.89-4.56) when holding other variables constant A one unit increase in the number of alcohol units consumed weekly increased the odds of having more severe disease (e.g. “severe” disease vs “mild” or “moderate” disease), when holding the other variables constant (odds ratio = 1.12, 95% confidence interval = 1.02-1.45) Way two: Individuals who had a pre-existing health condition had 2.31x higher odds of having more severe disease (e.g. “severe” disease vs “mild” or “moderate” disease) relative to individuals who did not have a pre-existing health condition (95% confidence interval = 1.45-4.56), when holding other variables constant Individuals who smoked had 1.45x higher odds of having more severe disease (e.g. “severe” disease vs “mild” or “moderate” disease) relative to individuals who did not smoke (95% confidence interval = 0.89-4.56) when holding other variables constant A one unit increase in the number of alcohol units consumed weekly increased the odds of having more severe disease (e.g. “severe” disease vs “mild” or “moderate” disease) by 1.12, when holding the other variables constant (95% confidence interval = 1.02-1.45) Which rows would be significant if you looked at the p-values and why? * Pre-existing_healthYes * Num_alcohol_units The 95% confidence interval around the odds ratio does not cross 1 for these comparisons (i.e. both the upper and the lower bound are higher than 1 OR both the upper and the lower bound are lower than 1). For SmokesYes, the 95% confidence interval crosses 1 (i.e. the lower confidence interval bound is below 1 and the higher confidence interval bound is above 1). This means when we look at the output, the p-value for SmokesYes will be above 0.05 (i.e. not significant). "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
