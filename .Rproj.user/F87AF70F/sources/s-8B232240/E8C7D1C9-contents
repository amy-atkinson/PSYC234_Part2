# Lecture 8 (Binary logistic regression) {#binary-log-regression}

```{r , include=FALSE}
library(tidyverse) 
library(DescTools)
```
## Lecture

This lecture comprises four parts:

**Part 1: Why do I need to worry about binary logistic regression?**

Part 1 covers why it is important to understand binary logistic regression, and why it is not appropriate to run a linear regression model when the outcome is continuous. It also covers an introduction to binary logistic regression.

Lecture recording:

Slides: 

**Part 2: Odds and odds ratios**

Part 2 introduces the concept of odds and odds ratios, and provides an example of how to calculate odds ratios manually (to aid in understanding about what odds and odds ratios represents).

Lecture recording:

Slides: 

**Part 3: Assumptions of binary logistic regression with one categorical predictor**

Part 3 covers the assumptions of binary logistic regression when you have one categorical predictor.

Lecture recording:

Slides: 

**Part 4: Running a binary logistic regression model (with one categorical predictor) in R**

Part 4 covers how to run a binary logistic regression model with one categorical predictor in R, and how to interpret the output.

Lecture recording:

Slides: 

## Lab preparation

Before the lab, please watch the following video. This walks you through how to run a binary logistic regression model with one categorical predictor in R.

The R markdown script covered in this video can be found here:

## Lab

In the lab, we'll run a binary logistic regression model with one categorical predictor in R.  Please download the following datafile: "reptile_data.csv".

The datasets relate to the following research question:

You are interested in whether the country an individual lives (UK/Australia) predicts reptile ownership (Yes/No). 

In the dataset, the outcome variable (reptile) is coded as “Y” and “N” (where Y = Yes and N = No)

To make sure we should all end up with the same output, set UK as your reference category for the "Country" variable.

1. Work through the following steps:

2. Prepare our data for analysis

3. Explore our data

4. Run the binary logistic regression model

5. Evaluate the model

6. Evaluate the individual predictors

7. Predicted probabilities

8. Interpret the output

## Lab - model script

Here is a model script that produces the answers to the above research question. I use the word 'model' loosely, as you may have used different functions you've learned over the last two years (and that's absolutely fine!). So don't worry if you haven't used the exact same functions as me. You should end up with the same results and interpretation at the end though.

### Binary logistic regression (with one categorical predictor)

```{r}
library(tidyverse) 
library(DescTools)
```

#### Read in the data

This chunk reads in the data.

```{r}
reptile_data <- read.csv("reptile_data.csv")
```

#### Prepare the data for analysis

##### Preparing our outcome variable:

Check the outcome is a numeric variable.

```{r}
str(reptile_data$Reptile)
```

Outcome is a character. Create a numeric variable and check the structure of this new variable:

```{r}
reptile_data$Reptile_numeric <- recode(reptile_data$Reptile, "N" = 0, "Y"= 1) 
str(reptile_data$Reptile_numeric)
```

Now let's view the data to see if this has worked well:

```{r}
view(reptile_data)
```

This chunk of code has worked well - "Reptile_numeric" equals 1 when "Reptile" equals "Y", and "Reptile_numeric"equals 0 when "Reptile" equals "N".

##### Preparing our predictor variable:

I want Country to be a factor with UK as the reference category. I therefore need country to be a factor with "UK" set as the first factor level. This chunk of code checks whether Country is a factor, and checks the order of the factor levels:

```{r}
str(reptile_data$Country)
```

County is a character. The folliwng chunk of code sets Country as factor and makes UK the first factor level. It then runs the "str" function again to checks this has worked well:

```{r}
reptile_data$Country <- factor(reptile_data$Country, c("UK", "Australia"))
str(reptile_data$Country)
```

Country is a factor, with UK is the first factor level. This will therefore be my reference category.

To double check this is true, we can also check using the constrasts function:

```{r}
contrasts(reptile_data$Country)
```

This confirms that UK will be our reference category.

##### Exploring the data:

```{r}
table(reptile_data$Country, reptile_data$Reptile_numeric)
```

From this, we can see that most people in the UK don't own a reptile. Whereas more than 50% of people in Australia do. 

We can also use this table to check for complete separation or quasi-complete separation - we have no cells with 0 so there's no evidence of complete separation or quasi-complete separation.

##### Running the analysis:

The following code runs the model and produces a summary of the output:

```{r}
country_model <- glm(Reptile_numeric ~ Country, data = reptile_data, family=binomial())

summary(country_model)

```

##### Evaluating the model:

###### Assessing the fit of the model:

This chunk of code produces the model chi square, the degrees of freedom and the p-value:

```{r}
country_model_chi <- country_model$null.deviance - country_model$deviance # produces model chi square
country_model_chi_df <- country_model$df.null - country_model$df.residual # produces model degrees of freedom
model_p <- 1 - pchisq(country_model_chi, country_model_chi_df) # produces model p-value


country_model_chi # chi square
country_model_chi_df # degrees of freedom
model_p # p-value
```

This indicates that adding country to our model significantly improved the fit, compared to the null model containing intercept only ($x^{2}$(1) = 5.49, *p* = .019).

##### Producing Pseudo $R^{2}

```{r}
PseudoR2(country_model, which = "all")
```

McFadden Pseudo $R^{2} = 0.12
CoxSnell Pseudo $R^{2} = 0.15
Nagelkerke Pseudo $R^{2} = 0.20

#### Evaluating the individual predictors:

##### Odds ratios:

```{r}
country_model_exponentiated <- exp(country_model$coefficients)
country_model_exponentiated
```

The odds of owning a reptile are higher for individuals who live in Australia relative to individuals who live in the UK (odds ratio = 5.63).

##### Confidence intervals around the odds ratio:

```{r}
country_model_odds_confidence_intervals <- exp(confint(country_model))
country_model_odds_confidence_intervals
```

The true odds ratio in the population is likely to be somewhere between 1.32 and 28.26. As the confidence intervals doesn't cross 1, the p-value for CountryAustralia is significant. This can be confirmed by examining the output of summary(country_model) above, in which the p-value is .025.

#### Predicted probabilities

```{r}
reptile_data$pred_prob <- fitted(country_model)
reptile_data$pred_prob
```

#### Overall interpretation of our model:

A binary logistic regression was conducted to examine whether country (UK/Australia) significantly predicted reptile ownership (yes/no). UK was set as the reference category for the country variable. The model predicted reptile ownership significantly better than the intercept-only model ($x^{2}(1) = 5.49, *p* = .019; McFadden Pseudo $R^{2} = 0.12, CoxSnell Pseudo $R^{2} = 0.15, Nagelkerke Pseudo $R^{2} = 0.20). Individuals who live in Australia had significantly higher odds of owning a reptile relative to individuals who live in the UK (Odds ratio = 5.63, 95% confidence interval = 1.32-28.26, *p* = .025).

## Worksheet:

The answers are in the next section.

### Activity 1: Calculating odds ratios manually

Activity 1 will involve work with the following data. You are a researcher interested in whether being excited (yes/no) predicts whether an individual passes their driving test (yes/no). Here is a table of frequencies.

```{r echo = FALSE} 
l8_w1 <- read.csv("l8_worksheet1.csv")
l8_w1_table <- table(l8_w1$Passed, l8_w1$Excited)
colnames(l8_w1_table) = c("Excited - No", "Excited - Yes")
rownames(l8_w1_table) = c("Passed - No", "Passed - Yes") 

l8_w1_table
```

**What are the odds of passing the driving test in the “Excited – Yes” group?**

**What are the odds of passing the driving test in the “Excited – No” group?**

**What is the odds ratio (where “Excited – No” is the original odds)?**
 
**What does this odds ratio mean?**

**Is there evidence of quasi-complete separation or complete separation here? Give a reason for your answer.**

### Activity 2: Interpreting R output

Activity 2 examines the following research question. You are a researcher interested in whether being rich (yes/no) predicts whether an individual owns a Tesla. Here is a table of frequencies:

```{r echo = FALSE} 
l8_w2 <- read.csv("l8_worksheet2.csv")
l8_w2_table <- table(l8_w2$Rich, l8_w2$Tesla)
colnames(l8_w2_table) = c("Tesla - Yes", "Tesla - No")
rownames(l8_w2_table) = c("Rich - No", "Rich - Yes") 

l8_w2_table
```

You analyse this data in R and the output of your model is below. For the outcome, you set “0” as “Has a Tesla – No” and “1” as “Has a Tesla – Yes” 

#### Model output

Here is the model output:

```{r}
l8_w2$tesla_numeric <- recode(l8_w2$Tesla, "No" = 0, "Yes"= 1) 
tesla_model <- glm(tesla_numeric ~ Rich, data = l8_w2, family=binomial())
summary(tesla_model)
```

#### Evaluating the model output

You run some code to produce the model’s chi-square statistic, the degrees of freedom and the p-value. These are displayed below:

Chi square = 8.2
Degrees of freedom = 1
P-value = 0.004

**What do these values indicate?**

#### Evaluating Pseudo R2

```{r}
PseudoR2(tesla_model, which = "all")
```

**Which Pseudo R2 values might you report (based on the lecture)?**

**What is the value of these Pseudo R2s?**

#### Evaluating the individual predictors

Looking back at the summary output, consider the following questions:

**What is the reference category for the predictor “Rich”?**

**What does the Intercept Estimate represent?**

**What does the RichYes Estimate represent?**

##### Exponentiating the estimates:

```{r}
tesla_model_exponentiated <- exp(tesla_model$coefficients)
tesla_model_exponentiated
```

**What does the Intercept represent?**

**What does the RichYes value represent?**

**Can you interpret the  RichYes value?**

##### Confidence intervals:

```{r}
tesla_model_odds_confidence_intervals <- exp(confint(tesla_model))
tesla_model_odds_confidence_intervals
```

**What does the RichYes 95% confidence intervals represent?**

**From the p-value in the summary table for the RichYes row, what can you conclude?**

**Is there another output we could look at to reach the same broad conclusion (regarding whether the predictor significantly predicts the outcome)?**

## Worksheet - answers

### Activity 1: Calculating odds ratios manually

```{r echo = FALSE} 
l8_w1 <- read.csv("l8_worksheet1.csv")
l8_w1_table <- table(l8_w1$Passed, l8_w1$Excited)
colnames(l8_w1_table) = c("Excited - No", "Excited - Yes")
rownames(l8_w1_table) = c("Passed - No", "Passed - Yes") 

l8_w1_table
```

**What are the odds of passing the driving test in the “Excited – Yes” group?**

<span style="color:purple">The probability of individuals who are excited (Excited – Yes) passing the driving test:</span>

<span style="color:purple">14/26 = 0.5384615385</span>

<span style="color:purple">14 is the number of participants who were excited and passed the driving test. </span>

<span style="color:purple">26 is the total number of individuals who responded “Excited – Yes” (14+12)</span>

<span style="color:purple">The probability of individuals who are excited (Excited – Yes) not passing the driving test: </span>

<span style="color:purple">12/26 = 0.4615384615</span>

<span style="color:purple">12 is the number of participants who were excited and did not pass the driving test.</span> 

<span style="color:purple">26 is the total number of individuals who responded “Excited – Yes” (14+12)</span>

<span style="color:purple">The odds of individuals who are excited passing the driving test:</span>

<span style="color:purple">0.5384615385 / 0.4615384615 = 1.1666666668</span>

**What are the odds of passing the driving test in the “Excited – No” group?**

<span style="color:purple">The probability of individuals who are not excited (Excited – No) passing the driving test:</span>

<span style="color:purple">8/37 = 0.216216216</span>

<span style="color:purple">8 is the number of participants who were not excited and passed the driving test. </span>

<span style="color:purple">37 is the total number of individuals who responded “Excited – No” (8+29)</span>

<span style="color:purple">The probability of individuals who are excited (Excited - No) not passing the driving test: </span>

<span style="color:purple">29/37 = 0.783783783</span>

<span style="color:purple">29 is the number of participants who were not excited and did not pass the driving test. </span>

<span style="color:purple">37 is the total number of individuals who responded “Excited – No” (8+29)</span>

<span style="color:purple">The odds of individuals who are not excited passing the driving test:</span>

<span style="color:purple">0.216216216 / 0.783783783 = 0.275862069</span>

**What is the odds ratio (where “Excited – No” is the original odds)?**

<span style="color:purple">1.1666666668  / 0.275862069 = 4.23</span>

<span style="color:purple">The odds ratio = 4.23</span>
 
**What does this odds ratio mean?**

<span style="color:purple">Individuals who were excited had a 4.23x higher odds of passing the driving test relative to individuals who were not excited.</span>

**Is there evidence of quasi-complete separation or complete separation here? Give a reason for your answer.**

<span style="color:purple">No – all cells have quite a few observations so there is no evidence of quasi-complete separation or complete separation.</span>

### Activity 2: Interpreting R output

Activity 2 examines the following research question. You are a researcher interested in whether being rich (yes/no) predicts whether an individual owns a Tesla. Here is a table of frequencies:

```{r echo = FALSE} 
l8_w2 <- read.csv("l8_worksheet2.csv")
l8_w2_table <- table(l8_w2$Rich, l8_w2$Tesla)
colnames(l8_w2_table) = c("Tesla - Yes", "Tesla - No")
rownames(l8_w2_table) = c("Rich - No", "Rich - Yes") 

l8_w2_table
```

You analyse this data in R and the output of your model is below. For the outcome, you set “0” as “Has a Tesla – No” and “1” as “Has a Tesla – Yes” 

#### Model output

Here is the model output:

```{r}
l8_w2$tesla_numeric <- recode(l8_w2$Tesla, "No" = 0, "Yes"= 1) 
tesla_model <- glm(tesla_numeric ~ Rich, data = l8_w2, family=binomial())
summary(tesla_model)
```

#### Evaluating the model output

You run some code to produce the model’s chi-square statistic, the degrees of freedom and the p-value. These are displayed below:

Chi square = 8.2
Degrees of freedom = 1
P-value = 0.004

**What do these values indicate?**

<span style="color:purple">$x^{2}$(1) = 8.20, *p* = .004.

<span style="color:purple">This indicates that adding the “Rich” variable to our model significantly improved the fit, compared to the null model containing intercept only</span>

#### Evaluating Pseudo R2

```{r}
PseudoR2(tesla_model, which = "all")
```

**Which Pseudo R2 values might you report (based on the lecture)?**

<span style="color:purple">McFadden, CoxSnell and Nagelkerke</span>

**What is the value of these Pseudo R2s?**

<span style="color:purple">McFadden = 0.19
CoxSnell = 0.16
Nagelkerke = 0.27</span>

#### Evaluating the individual predictors

Looking back at the summary output, consider the following questions:

**What is the reference category for the predictor “Rich”?**

<span style="color:purple">“No” is our reference category for the Rich variable</span>

**What does the Intercept Estimate represent?**

<span style="color:purple">The log odds of someone with a Rich value of “No” having a tesla</span>

**What does the RichYes Estimate represent?**

<span style="color:purple">The change in the log odds of having a tesla value of “Yes” when going from the reference category (RichNo) to RichYes</span>

##### Exponentiating the estimates:

```{r}
tesla_model_exponentiated <- exp(tesla_model$coefficients)
tesla_model_exponentiated
```

**What does the Intercept represent?**

<span style="color:purple">The odds of having a tesla for individuals who are not rich</span>

**What does the RichYes value represent?**

<span style="color:purple">The change in odds (i.e. the odds ratio) of having a tesla (i.e. tesla = yes) when going from RichNo to RichYes</span>

**Can you interprert the RichYes value?**

<span style="color:purple">The odds of having a tesla are 11.33x higher if you are rich than if you are not rich</span>

##### Confidence intervals:

```{r}
tesla_model_odds_confidence_intervals <- exp(confint(tesla_model))
tesla_model_odds_confidence_intervals
```

**What does the RichYes 95% confidence intervals represent?**

<span style="color:purple">The 95% confidence around the odds ratio (for the comparison between RichNo to RichYes).</span>

**From the p-value in the summary table for the RichYes row, what can you conclude?**

<span style="color:purple">Whether an individual is rich (yes/no) significantly predicts whether they have a tesla (yes/no; *p* = .005)</span>

**Is there another output we could look at to reach the same broad conclusion (regarding whether the predictor significantly predicts the outcome)?**

<span style="color:purple">Yes, you could also look at the output for the 95% confidence interval around the odds ratio. As both the lower and upper bound of the confidence interval are above 1, this indicates that the p-value would be significant - whether an individual is rich (yes/no) significantly predicts whether they have a tesla (yes/no)</span>