# Preface

title: "PSYC234: Lectures 5-9"
author: "Dr Amy Atkinson"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
output: bookdown::gitbook
documentclass: book
description: "This contains all of the important documents for Dr Amy Atkinson's part of PSYC234 (Lectures 5-9)"
---

---
site: "bookdown::bookdown_site"
output:
  bookdown::gitbook:
    lib_dir: "book_assets"
  bookdown::pdf_book:
    keep_tex: yes
---

```{r}
bookdown::render_book("index.Rmd", "bookdown::gitbook")
```

<!--chapter:end:index.Rmd-->

# Lecture 5 (Binomial Test) {#binomial_test}

## Lecture

Only one part of this lecture covers the binomial test. The other part covers factor analysis with Emma Mills.

The lecture recording is available here:

The slides are available here:

## Code in R

There is no lab covering the binomial test (the lab covers factorial analysis you covered in the first half of the lecture with Emma instead). But don't worry, the code to run a binomial test in really simple... You don't even need to install any packages.

The code is:

binom.test(number of successes, total number of trials, known proportion you are interested in comparing the sample to)

Here is an example from the lecture:

Participants were asked: "Is the moon made of cheese? Yes/No". 

You are interested in whether the proportion of participants answering the question correctly differs from  chance guessing rate.

14 participants were asked the question and 13 answered correctly.

There are two possible answers, so participants have a 50% chance of answering the question correctly even if they just guess. 50% experessed as a proportion is 0.5.

So the code to run this would be:

```{r}
binom.test(13, 14, 0.5)
```

## Worksheet:

### Activity 1: One sample-test or binomial test?

Disclaimer: All data is made up (and these estimates may be utterly ridiculous!)

The answers are in the next section.

For the following examples, write down whether you think the test conducted should be a one-sample t-test or a binomial test. 

1. You are the coach of a football team. You are interested in whether the running distance of your players significantly differs from the England national football team. You know, on average, England football players run 10km per game. 

2. You are the coach of a football team. You are interested in whether the proportion of games your team scores a goal is significantly different from that of the England national team. You know that on average, the England national team scores a goal in 60% of games. 

3. You are a university lecturer. You decide to introduce post-lecture worksheets to help students to consolidate knowledge learned during lectures. You are interested in whether the proportion of students passing the class test differs between this year and last year. You don’t have individual marks for last year’s students, but you do know that 74% of the last year’s cohort passed the class test. 

4. You are a university lecturer. You decide to introduce post-lecture worksheets to help students to consolidate knowledge learned during lectures. You are interested in whether the score on the class test differs between this year and last year. You know that last year, the average mark on the class test was 62% (or 0.62 expressed a proportion).

5. You are a neonatal doctor (a doctor who specialising in caring for newborn babies). You think that babies born in your hospital are quite small. You are interested in whether the proportion of babies who are classed as “small for gestational age” differs between your hospital and the UK average (10%). 

6. You are a neonatal doctor (a doctor who specialising in caring for newborn babies). You think that babies that are born in your hospital are quite small. You are interested in whether the average weight of babies born at your hospital is significantly less than the UK average (3350g). 

### Activity 1: Answers

1. One-sample t-test. The value for each individual is continuous.You are interested in whether the mean number of km runs differs from a known value. 

2. Binomial test. Two possible outcomes: team scores or team does not score). You are interested in whether the proportion that a given outcome occurs (i.e. your team scores a goal) differs from a known value. 

3. Binomial test. Two possible outcomes: Each student’s outcome is either “passed class test” or “failed class test”. You are interested in whether the proportion that a given outcome occurs (i.e. passes the class test) differs from a known value.

4. One-sample t-test. The value for each individual is continuous. You are interested in whether the mean score students get differs from a known value.

5. Binomial test. Two possible outcomes: Each baby’s outcome is either “small for gestational age” or “not small for gestational age”. You are interested in whether the proportion that a given outcome occurs (i.e. small for gestational age) differs from a known value.

6. One-sample t-test. The value for each individual is continuous. You are interested in whether the mean weight of babies at your hospital differs from a known value.

Take-home message: A one sample t-test is used when you are interested in comparing the mean of a sample to a known value. The binomial test is used when you are interested in comparing a sample’s proportion of “successes” to a known value.

### Activity 2: Identifying “success”

1. You are a lecturer interested in whether the proportion of students passing your module differs from your colleague’s module. 82% of students (or 0.82 expressed as a proportion) pass your colleague’s module.

2. You are the headteacher of a grammar school which has an entrance exam. You are interested in whether the proportion of children failing the test differs significantly from last year. The failure rate last year was 24% (or 0.24 expressed as a proportion). 

3. You are a teacher. You are interested in whether the proportion of students in your class with special educational needs and disabilities (SEND) significantly differs from the year group average (27%, or 0.27 expressed as a proportion). 

4. You have developed a new flu vaccine. You are interested in whether the proportion of people who develop side effects after your vaccine differs from the flu vaccine currently used by the NHS (37%, or 0.37 expressed as a proportion).  

### Activity 2: Answers

1. Success: pass the module. 
   Failure: fail the module.

2. Success: failing the test.
   Failure: passing the test.
   
3. Success: Has special educational needs.
   Failure: Does not have special educational needs.
   
4. Success: Has side effects.
   Failure: Does not have side effects.
   
Take home message: Success refers to the outcome you are interested in. Sometimes this might be counterintuitive to how we typically think about ‘success’. 

<!--chapter:end:01-Binomial_test.Rmd-->

# Lecture 6 (Non-parametric tests: Wilcoxon rank-sum and Wilcoxon signed-rank tests) {#wilcoxon-rank-sum-signed-rank}

```{r set, include=FALSE}
library(tidyverse) 
library(knitr)
library(kableExtra)
```
## Lecture

This lecture comprises three parts:

**Part 1: An introduction to non-parametric tests** 

Part 1 covers an introduction to non-parametric tests and why they might be useful to consider.

Lecture recording:

Slides: 

**Part 2: The Wilcoxon rank-sum test** 

Part 2 introduces you to the Wilcoxon rank-sum test. This includes when to use this test, the theory behind it ,  how the test statistic would be calculated manually, how to run the test in R, and how to interpret the output:

Lecture recording:

Slides: 

**Part 3: The Wilcoxon signed-rank test** 

Part 3 introduces you to the Wilcoxon signed-rank test, covering when to use the test, the theory behind it, how to calculate the test statistic manually, how to run the test in R and how to interpret the output:

Lecture recording:

Slides: 

## Lab preparation

Before the lab, please watch the following video. This walks you through how to perform a Wilcoxon rank-sum test and Wilcoxon signed-rank test in R.

The R markdown script covered in this video can be found here:

## Lab

In the lab, we'll practice running a Wilcoxon rank-sum and Wilcoxon signed-rank test in R. Please download the following zip file which contains two datasets: "apple_study_data.csv" and "banana_study_data.csv. 

The datasets relate to the following research questions:

**1. Apple dataset**

You are a researcher interested in whether the old saying "an apple a day keeps the doctor away is true". You recruit 16 people and assign each participant to either a "0 apples" or "1 apple" condition. Participants in the "0 apple" condition eat 0 apples every day for a year. Participants in the "1 apple" condition eat 1 apple a day for a year.  You ask participants to report how many times they visited the GP in the year.

**2. Banana dataset**

You are interested in whether eating bananas keeps the doctor away. 

This time you recruit only one group of participants. In the first year, you ask them to eat 0 banana every day. In the second year, you ask them to eat 1 bananas a day. You ask them to report how many times they visit the GP in Year 1 and Year 2. 

Consider each research question, perform the normality checks, and then the appropriate analyses.

## Lab - model script

Here is a model script that produces the answers to the above research questions. I use the word 'model' loosely, as you may have used different functions you've learned over the last two years (and that's absolutely fine!). So don't worry if you haven't used the exact same functions as me. You should end up with the same results and interpretation at the end though.

### Load in the libraries we need

```{r setup}
library(tidyverse) 
library(cowplot)
```

### Research question 1:

Background: You are a researcher interested in whether the old saying "an apple a day keeps the doctor away is true". You recruit 16 people and assign each participant to either a "0 apples" or "1 apple" condition. Participants in the "0 apple"" condition eat 0 apples every day for a year. Participants in the "1 apple" condition eat 1 apple a day for a year. You ask participants to report how many times they visited the GP in the year.

### Read in the data

```{r}
apple_data <- read.csv("apple_study_data.csv")
```

### Check whether the data meets the assumption of normality


#### 0 apples group:


##### Filter data:

This produces a new dataset containing data for the 0 apple a day group only:

```{r}
zero_apples <- apple_data %>% filter(Apples_per_day == "0 apples")  
```


##### Produce a Q-Q plot:

```{r}
qqnorm(zero_apples$Visits) # plots observed data
qqline(zero_apples$Visits, col = "steelblue") # plots expected data if data follows a normal distribution
```

Some evidence of deviation. 

##### Shapiro-Wilk test:

```{r}
shapiro.test(zero_apples$Visits)

```

This suggests that the data in the zero apples group violates the assumption of normality.

#### 1 apple group:

##### Filter data:

This produces a new dataset containing data for the 1 apple a day group only:

```{r}
one_apple <- apple_data %>% filter(Apples_per_day == "1 apple")

```

##### Produce a Q-Q plot:


```{r}
qqnorm(one_apple$Visits) # qqnorm plots our data

qqline(one_apple$Visits, col = "steelblue") # plots expected data if the data are from a normally distributed population.
```

The data in this group seems to follow the diagonal line quite well. 

##### Shapiro-Wilk test:

```{r}
shapiro.test(one_apple$Visits)
```

The Shapiro-Wilk test suggests the assumption of normality is not violated for this group

### Exploring our dataset:

Medians, range, and number of participants per group:

```{r}
apple_data %>% # 
  group_by(Apples_per_day) %>% # plots data per group
  summarise(med = median(Visits), # median Visits value 
            min = min(Visits), # lowest Visits value
            max = max(Visits), # highest Visits value
            n = n()) # number of participants per group
```

Plot:

```{r}
ggplot(apple_data, aes(x=Apples_per_day, y=Visits)) + 
  geom_boxplot() + 
  labs(y = "Number of visits to the GP") + 
  theme_cowplot() 
```

The median for the 1 apple group is lower than the median for the 0 apple group. There are 8 participants in each group.

### Performing the Wilcoxon rank-sum test:

```{r}
model1 <- wilcox.test(Visits ~ Apples_per_day, data = apple_data, paired = FALSE) 
model1
```

There is a significant difference between the groups (*p* = .018).

### Effect size: 

```{r}
z <- qnorm(model1$p.value/2)
r <- z/sqrt(16) # earlier, we saw we have 8 participants in each Apples_per_day, so 16
r

```

The effect size (*r*) is equal to -0.59. This is a large effect size.  


### Interpretation:

A Wilcoxon rank-sum test revealed that the participants who ate one apple a day (Median = 3.5; Range = 0-8) visited the GP less than participants who ate zero apples a day (Median = 9.5; Range = 2-41), *W* = 55, *p* = .018, *r* = -.59. 

This study provides evidence that an apple a day  keep the doctor away.

### Research question 2:

You are interested in whether eating bananas keeps the doctor away. This time you recruit only one group of participants. In the first year, you ask them to eat 0 banana every day. In the second year, you ask them to eat 1 bananas a day. You ask them to report how many times they visit the GP in Year 1 and Year 2. 

### Read in the data

This chunk reads in the data.

```{r}
banana_data <- read.csv("banana_study_data.csv") 
```

### Check whether the data meets the assumption of normality

```{r}
banana_data$difference <- banana_data$zero_banana - banana_data$one_banana 
```

#### Produce the Q-Q plot:

```{r}
qqnorm(banana_data$difference) # qqnorm plots our data

qqline(banana_data$difference, col = "steelblue") # plots expected data if the data are from a normally distributed population.
```

### Shapiro-Wilk test:

A few of the points deviate from the line. This suggests the assumption of normality may be violated.

```{r}
shapiro.test(banana_data$difference)

```

The p-value is significant, this suggests the assumption of normality has been violated. 

### Exploring the data:

#### Descriptive statistics:

```{r}
banana_data %>%
  summarise(med_0banana = median(zero_banana), min_0banana = min(zero_banana), max_0banana = max(zero_banana), # median, min and max for 0 banana timepoint,
            med_1banana = median(one_banana), min_1banana = min(one_banana), max_1banana = max(one_banana), # median, min and max for 1 banana timepoint
            n()) # number of participants
```
            
#### Plot:

Firstly, we need our data to be in long format:

```{r}
banana_data_long <- gather(banana_data, Bananas, Visits, zero_banana:one_banana)
banana_data_long 

banana_data_long$Bananas <- factor(banana_data_long$Bananas, c("zero_banana", "one_banana")) # this will mean zero bananas is presented first on the plot
```

Then produce the plot:
```{r}
ggplot(banana_data_long, aes(x=Bananas, y=Visits)) + 
  geom_boxplot() +
  labs(y = "Number of GP visits") +
  scale_x_discrete(labels = c("Zero", "One")) + # changes "zero_banana" to "Zero" and "one_banana" to "One" - you could also recode the variable to do the same thing
  theme_cowplot()
```

The median number of visits to the GP is lower in the zero banana condition than the one banana condition.

### Performing the Wilcoxon signed-rank test:

```{r}
model2 <- wilcox.test(banana_data$zero_banana, banana_data$one_banana, paired = TRUE)
model2
```

The p-value is equal to 0.03552 (or .036), indicating there is a significant difference between the conditions.

### Effect size: 

```{r} 
z_bananas <- qnorm(model2$p.value/2)
r_banana <- z_bananas/sqrt(12) # 12 because we have 12 observations overall (6 participants and 2 timepoints for each)
r_banana
```

The effect size (*r*) is equal to -0.61, indicating there is a large effect size.

### Interpretation:

A Wilcoxon signed-rank test revealed that the number of visits to the GP was significantly lower in the 0 banana condition (Median = 5; Range = 1-22) than the 1 apple a day condition (Median = 28; Range = 3-65), *V* = 0, *p* = .036, *r* = -.61. 

Given that participants who ate one banana a day visited the doctor more than participants who ate zero apples a day, this study provides evidence that eating a banana a day does not keep the doctor away 

(Disclaimer: data are 100% made up, please don't stop eating bananas based on this...!)

## Worksheet:

The answers are in the next section.

### Activity 1: Calculating test statistics manually

#### Wilcoxon rank-sum test

You are a researcher interested in whether the number of cups of coffee drank affects how many admin tasks participants can get done in an hour. You assign to one of two conditions (drink 4 cups of coffee a day or drink 0 cups of coffee a day). After a week, you ask participants to come into the lab and ask them to complete a range of admin tasks. You count how many admin tasks they manage to complete. The data are below. 

Use this data to calculate the test statistic manually:

```{r echo = FALSE} 
Group <- c("4 cups", "4 cups", "4 cups", "0 cups", "0 cups", "0 cups", "0 cups")
Tasks_completed <- c(5, 18, 14, 6, 4, 17, 14)
tab1 <- data.frame(Group, Tasks_completed)
knitr::kable(tab1, booktabs = TRUE, align=rep('c', 2)) %>%
  kable_styling(position = "center")
```

Steps:

1.	First rank the data

2. Sum the ranks for each group

3.	Calculate the mean rank for each group

4.	Calculate the sum of ranks minus mean rank for each group

5.	What is the test statistic?

6.	What might R report as the test statistic and why?

#### Wilcoxon signed-rank test

You are a researcher interested in whether a reading intervention helps children. You assess children’s reading skills and then give them all an intensive reading intervention. You then measure their reading abilities again. 

Use this data to calculate the test statistic manually

```{r echo = FALSE} 
Before_intervention <- c(23, 34, 67, 65, 21)
After_intervention <- c(27, 34, 91, 67, 44)
tab2 <- data.frame(Before_intervention, After_intervention)
knitr::kable(tab2, booktabs = TRUE, align=rep('c', 2)) %>%
  kable_styling(position = "center")
```

1.	Calculate the difference between “Before intervention” and “After intervention”

2.	Note whether the difference is positive or negative

3.	Rank the difference

4. 4.	Next, add up positive ranks and negative ranks

5.	What is the test statistic (T)?

6.	R reports a test statistic “*V*” instead of R.  What might *V* equal to? Why might *V* equal to two values?

### Activity 2: Interpreting R output

Interpret the following R output. Part 1 uses an independent groups design. Part 2 uses a repeated measures design. Please note, this data are different to that used in Activity 1 (so the test statistics will be different).

#### An independent groups design

##### Testing the assumption of normality 

###### Group 1:
```{r echo = FALSE} 
worksheet_activity1 <- read.csv("l6_worksheet1.csv")
group1 <- worksheet_activity1 %>% filter(Group == 1)

qqnorm(group1$Outcome) 
qqline(group1$Outcome, col = "steelblue") 

shapiro.test(group1$Outcome)
```

###### Group 2:
```{r echo = FALSE} 
group2 <- worksheet_activity1 %>% filter(Group == 2)

qqnorm(group2$Outcome) 
qqline(group2$Outcome, col = "steelblue") 

shapiro.test(group2$Outcome)
```

Is the assumption violated?

##### Interpret the descriptive statistics and the model output

```{r echo = FALSE} 
model1 <- wilcox.test(Outcome ~ Group, data = worksheet_activity1, paired = FALSE)
model1

worksheet_activity1 %>%
  group_by(Group) %>%
  summarise(med = median(Outcome),
            min = min(Outcome),
            max = max(Outcome),
            n())
```

What can we conclude? Report in APA format.

How was the p-value calculated? 

#### A repeated measures design

You are a researcher interested in whether the amount of chocolate eaten is different before and after the participant goes a diet. 

##### Testing the assumption of normality 

```{r echo = FALSE} 
worksheet_activity2 <- read.csv("l6_worksheet2.csv")

worksheet_activity2$Difference <- worksheet_activity2$Before - worksheet_activity2$After

qqnorm(worksheet_activity2$Difference) 
qqline(worksheet_activity2$Difference, col = "steelblue") 

shapiro.test(worksheet_activity2$Difference)
```

Is the assumption violated?

##### Interpret the descriptive statistics and the model output

```{r echo = FALSE} 
model2 <- wilcox.test(worksheet_activity2$Before, worksheet_activity2$After, paired = TRUE)
model2

worksheet_activity2 %>%
  summarise(median_before = median(Before), median_after = median(After),
            min_before = min(Before), min_after = min(After),
            max_before = max(Before), max_after = max(After),
            n())
```

What can we conclude? Report in APA format.

How was the p-value calculated? 

## Worksheet answers:

### Activity 1: Answers

#### Wilcoxon rank-sum test

Steps:

**1.	First rank the data**

```{r echo = FALSE} 
Group <- c("4 cups", "4 cups", "4 cups", "0 cups", "0 cups", "0 cups", "0 cups")
Tasks_completed <- c(5, 18, 14, 6, 4, 17, 14)
Rank <- c(2, 7, 4.5, 3, 1, 6, 4.5)
tab3 <- data.frame(Group, Tasks_completed, Rank)
kable(tab3, booktabs = TRUE, align=rep('c', 3)) %>%
  kable_styling(position = "center")
```

**2.	Sum the ranks per group**

<span style="color:purple">4 cups = 13.5</span>

<span style="color:purple">0 cups = 14.5</span>

**3.	Calculate the mean rank per group**

<span style="color:purple">4 cups = 3\*4 = 12. 12/2 = 6</span>

<span style="color:purple">0 cups = 4\*5 = 20. 20/2 = 10</span> 

**4.	Calculate the sum of ranks minus mean rank per group**

<span style="color:purple">4 cups = 13.5-6 = 7.5</span>

<span style="color:purple">0 cups = 14.5-10 = 4.5</span>

**5.	What is the test statistic?**

<span style="color:purple">Test statistic = The lowest sum of ranks. Test statistic = 4.5</span>

**6.	What might R report as the test statistic and why?**

<span style="color:purple">R reports the test statistic (*W*) as the sum of ranks minus the mean rank for the first factor level. R may therefore report the test statistic as 4.5 or 7.5.</span>

#### Wilcoxon signed-rank test

**1.	Calculate the difference between “Before intervention” and “After intervention”**

```{r echo = FALSE} 
Before_intervention <- c(23, 34, 67, 65, 21)
After_intervention <- c(27, 34, 91, 67, 44)
Difference <- c(-4, "Exclude", -24, -2, -23)
tab4<- data.frame(Before_intervention, After_intervention, Difference)
kable(tab4, booktabs = TRUE, align=rep('c', 3)) %>%
  kable_styling(position = "center") %>%
  column_spec(3, color = "purple")
```

**2.	Note whether the difference is positive or negative**

```{r echo = FALSE} 
Before_intervention <- c(23, 34, 67, 65, 21)
After_intervention <- c(27, 34, 91, 67, 44)
Difference <- c(-4, "Exclude", -24, -2, -23)
Sign <- c("Negative", "", "Negative", "Negative", "Negative")
tab5<- data.frame(Before_intervention, After_intervention, Difference, Sign)
kable(tab5, booktabs = TRUE, align=rep('c', 4)) %>%
  kable_styling(position = "center") %>%
    column_spec(3, color = "purple") %>%
    column_spec(4, color = "purple")

```

**3.	Rank the difference**

```{r echo = FALSE} 
Before_intervention <- c(23, 34, 67, 65, 21)
After_intervention <- c(27, 34, 91, 67, 44)
Difference <- c(-4, "Exclude", -24, -2, -23)
Sign <- c("Negative", "", "Negative", "Negative", "Negative")
Rank <- c("2", "", "4", "1", "3")
tab6<- data.frame(Before_intervention, After_intervention, Difference, Sign, Rank)
kable(tab6, booktabs = TRUE, align=rep('c', 5)) %>%
  kable_styling(position = "center") %>%
      column_spec(3, color = "purple") %>%
      column_spec(4, color = "purple") %>%
      column_spec(5, color = "purple")
```

**4.	Next, add up positive ranks and negative ranks**

<span style="color:purple">Positive ranks: 0</span>

<span style="color:purple">Negative ranks: 10</span>

**5.	What is the test statistic (*T*)?**

<span style="color:purple">*T* = 0</span>

**6.	R reports a test statistic “*V*” instead of R.  What might *V* equal to? Why might *V* equal to two values?**

<span style="color:purple">*V* = 0 or 10. *V* is equal to the sum of positive ranks. But whether ranks are positive or negative depends on whether you enter “before” or “after” first into the wilcox.test function (as this determines whether you calculate the difference by doing before-after or after-before).</span>

### Activity 2: Answers

### An independent groups design:

#### Testing the assumption of normality 

##### Group 1:
```{r echo = FALSE} 
qqnorm(group1$Outcome) 
qqline(group1$Outcome, col = "steelblue") 

shapiro.test(group1$Outcome)
```

##### Group 2:
```{r echo = FALSE} 
qqnorm(group2$Outcome) 
qqline(group2$Outcome, col = "steelblue") 

shapiro.test(group2$Outcome)
```

**Is the assumption violated?**

<span style="color:purple">Group 1: The assumption of normality is violated. Quite a few points deviate from the line in the Q-Q plot and the Shapiro-Wilk test is significant.</span>

<span style="color:purple">Group 2: The assumption of normality is not violated. The dots generally follow the line well in the Q-Q plot and the Shapiro-Wilk test is non-significant.</span>

#### Interpret the descriptive statistics and the model output

```{r echo = FALSE} 
model1 <- wilcox.test(Outcome ~ Group, data = worksheet_activity1, paired = FALSE)
model1

worksheet_activity1 %>%
  group_by(Group) %>%
  summarise(med = median(Outcome),
            min = min(Outcome),
            max = max(Outcome),
            n())
```

**What can we conclude? Report in APA format.**

<span style="color:purple">The Wilcoxon rank-sum test revealed no significant difference between Group 1 (Median = 17, Range = 1-35) and Group 2 (Median = 5.5, Range = 2-9; *W* = 19, *p* = 0.936).</span>

<span style="color:purple">Note: In practice, you should also calculate the effect size and report that.</span>

**How was the p-value calculated?**

<span style="color:purple">The normal approximation with the continuity correction</span>

### A repeated measures design

#### Testing the assumption of normality 

```{r echo = FALSE} 
qqnorm(worksheet_activity2$Difference) 
qqline(worksheet_activity2$Difference, col = "steelblue") 

shapiro.test(worksheet_activity2$Difference)
```

**Is the assumption violated?**

<span style="color:purple">The assumption of normality is violated. Some points deviate quite a bit from the line in the Q-Q plot and the Shapiro-Wilk test is significant.</span>

#### Interpret the descriptive statistics and the model output

```{r echo = FALSE} 
model2

worksheet_activity2 %>%
  summarise(median_before = median(Before), median_after = median(After),
            min_before = min(Before), min_after = min(After),
            max_before = max(Before), max_after = max(After),
            n())
```

**What can we conclude? Report in APA format.**

<span style="color:purple">The Wilcoxon signed-rank test revealed that participants ate significantly more grams of chocolate before the diet (Median = 232, Range = 230-235) than after the diet (Median = 18; Range = 4-33), *V* = 36, *p* = 0.014.</span>

<span style="color:purple">Note: In practice, you should also calculate the effect size and report that.</span>

**How was the p-value calculated?**

<span style="color:purple">The normal approximation with the continuity correction</span>

<!--chapter:end:02-Non-parametric-tests-1.Rmd-->

# Lecture 7 (Non-parametric tests: Kruskal-Wallis test and Friedman's ANOVA) {#kruskal-friedman}

```{r set, include=FALSE}
library(tidyverse) 
library(knitr)
library(kableExtra)
options(scipen=999)
```
## Lecture

This lecture comprises two parts:

**Part 1: Assessing normality with three or more independent groups and the Kruskal-Wallis test**

Part 1 covers how to assess the assumption of normality with three or more independent groups. It also covers the theory behind the Kruskal-Wallis test, how to calculate the Kruskal-Wallis test statistic manually, how to run the test in R,  how to interpret the output, and how to conduct post-hoc comparisons.

Lecture recording:

Slides: 

**Part 2: Assessing normality with three or more repeated measures and Friedman's ANOVA**

Part 2 covers how to assess the assumption of normality with three or more repeated measures. It also covers Friedman's ANOVA, including: the theory behind the test, how to calculate the test statistic manually, how to run the test in R and how to interpret output, and how to conduct post-hoc comparisons.

Lecture recording:

Slides: 

## Lab preparation

Before the lab, please watch the following video. This walks you through how to perform Friedman's ANOVA in R.

Please also take a look at this R markdown file. This covers how to run a Kruskal-Wallis test and Friedman's ANOVA in R:  

## Lab

In the lab, we'll practice running a Kruskal-Wallis test and Friedman's ANOVA in R. Please download the following zip file which contains two datasets: "course_data_set.csv" and "memory_data.csv". 

The datasets relate to the following research questions:

**1. Course dataset**

You are a psychology lecturer. You hear that the library is offering three statistics courses. You are interested in whether students who attend the courses perform significantly differently from each other.

You recruit 18 people and assign each one to a course. After the courses are finished, you ask them to write an R script. You time how long it takes students to complete the task. You are interested in whether there is a significant effect of course on the time taken to complete the task.

**2. Memory dataset**

You are a developmental psychologist. You are interested in whether working memory develops between 15 and 17 years of age.

You recruit a sample of adolescents and test them on a working memory task when they are 15 years of age, 16 years of age, and 17 years of age. 

You then examine whether there is a significant effect of age on working memory score.

## Lab - model script

Here is a model script that produces the answers to the above research questions. I use the word 'model' loosely, as you may have used different functions you've learned over the last two years (and that's absolutely fine!). So don't worry if you haven't used the exact same functions as me. You should end up with the same results and interpretation at the end though.

---
title: "Week 17 - Lab model script"
author: "Amy Atkinson"
date: "16/02/2022"
output: html_document
---

### Course data:

```{r setup}
library(tidyverse) 
library(cowplot)
library(FSA)
library(PMCMRplus)
```

#### Read in the data

This chunk reads in the data.

```{r}
course_data <- read.csv("course_data_set.csv")
```

#### Check whether the data meets the assumption of normality

Remember, we need to check if the assumption of normality is met for each group separately.

##### Course 1

###### Filter data:

This produces a new dataset containing data for the Course 1 group only:

```{r}
course_1 <- course_data %>% filter(Group == "Course 1")
```

###### Produce a Q-Q plot:

```{r}
qqnorm(course_1$Time)
qqline(course_1$Time, col = "steelblue")
```

Quite a few of the datapoints deviate from the line, suggesting data from this group might violates the assumption of normality.

###### Shapiro-Wilk test:


```{r}
shapiro.test(course_1$Time)
```

This suggests that the data in the course 1 group violates the assumption of normality.

##### Course 2:

###### Filter data:

This produces a new dataset containing data for the Course 2 group only:

```{r}
course_2 <- course_data %>% filter(Group == "Course 2")
```

###### Produce a Q-Q plot:


```{r}
qqnorm(course_2$Time)
qqline(course_2$Time, col = "steelblue")
```

The points do generally follow the line, although there is some slight deviation.

###### Shapiro-Wilk test:

```{r}
shapiro.test(course_2$Time)
```

The Shapiro-Wilk test is not significant, suggesting the data does not violate the assumption of normality.

##### Course 3:

###### Filter data:

This produces a new dataset containing data for the Course 3 group only:

```{r}
course_3 <- course_data %>% filter(Group == "Course 3")
```

###### Produce a Q-Q plot:


```{r}
qqnorm(course_3$Time)
qqline(course_3$Time, col = "steelblue")
```

Quite a few of the points deviate from the line. 

###### Shapiro-Wilk test:

```{r}
shapiro.test(course_3$Time)
```

The Shapiro-Wilk test suggests that data in this group violates the assumption of normality.

###### Interpretation:

Data from the Course 1 and Course 3 groups appears to violates the assumption of normality. Data from the Course 2 group does not appear to violate the assumption. We might therefore decide to run the Kruskal-Wallis test. 

#### Exploring our dataset:

First, let's explore the data.

##### Descriptive statistics:

Medians, range, and number of participants per group:

```{r}
course_data %>% 
  group_by(Group) %>% # plots data per group
  summarise(med = median(Time), # median  
            min = min(Time), # lowest value
            max = max(Time), # highest value
            n = n()) # number of participants per group
```

Plot:

```{r}
ggplot(course_data, aes(x=Group, y=Time)) + 
  geom_boxplot() + 
  labs(y = "Time spent completing the task (minutes)") + 
  theme_cowplot() 
```

The median for the Course 3 group is lowest, Course 2 is intermediate, and Course 1 is highest. There are 6 participants in each group


#### Performing the Kruskal-Wallis test:

```{r}
model1 <- kruskal.test(Time ~ Group, data = course_data)
model1
```

From this, we can see that there is a significant difference between the groups.

#### Post-hoc tests:

Post-hoc tests were therefore conducted to understand which groups significantly differ from each other.

```{r}
dunnTest(Time~Group,data=course_data, method = "holm")
```

Here, we can see that the difference between Course 1 and Course 3 is significant.

#### Interpretation:

There was a significant effect of course on the amount of time required to complete the task, *H*(2) = 7.77, *p* = .020. Post-hoc comparisons were conducted using Dunn’s test. P-values were corrected using Bonferroni-Holm. There was a significant difference between Course 1 (median = 64, range = 21-70) and Course 3 (median = 8.50, range = 5-31; *p* = .016), with students who completed Course 3 completing the task faster. No significant difference emerged between Course 1 and Course 2 (median = 25.5, range = 15-36; *p* = 0.303), or Course 2 and Course 3 (*p* = .176).

###  Memory data:

#### Read in the data

This chunk reads in the data.

```{r}
memory_data <- read.csv("memory_data.csv") 
```

#### Check whether the data meets the assumption of normality

##### Timepoint 1 (Age 15):

###### Produce a Q-Q plot:


```{r}
qqnorm(memory_data$Age_15)
qqline(memory_data$Age_15, col = "steelblue")
```

Some of the points deviate quite a lot from the line. This suggests the assumption of normality may be violated. 

###### Shapiro-Wilk test:

```{r}
shapiro.test(memory_data$Age_15)
```

The Shapiro-Wilk test is significant, suggesting the assumption of normality is violated.

##### Timepoint 2 (Age 16):

###### Produce a Q-Q plot:

```{r}
qqnorm(memory_data$Age_16)
qqline(memory_data$Age_16, col = "steelblue")
```

The points generally follow the line well.  

###### Shapiro-Wilk test:

```{r}
shapiro.test(memory_data$Age_16)
```

The Shapiro-Wilk test is non-significant and most of the points follow the line, suggesting the assumption of normality is  not violated.

##### Timepoint 3 (Age 17):

###### Produce a Q-Q plot:

```{r}
qqnorm(memory_data$Age_17)
qqline(memory_data$Age_17, col = "steelblue")
```

The points deviate from the line quite a bit. 

###### Shapiro-Wilk test:

```{r}
shapiro.test(memory_data$Age_17)
```

The Shapiro-Wilk test is significant, suggesting the assumption of normality may have been violated.

###### Interpretation:

Data from the Age_15 and Age_17 timepoints appears to violate the assumption. A Friedman's ANOVA will therefore be run. 

#### Exploring the data:

##### Examining the descriptive statistics:

Median, minimum, maximum per condition: 

```{r}
memory_data %>%
  summarise(med_Age_15 = median(Age_15), med_Age_16 = median(Age_16), med_Age_17 = median(Age_17), 
            min_Age_15 = min(Age_15), min_Age_16 = min(Age_16), min_Age_17 = min(Age_17),
            max_Age_15 = max(Age_15), max_Age_16 = max(Age_16), max_Age_17 = max(Age_17),
            n = n()) # n only need to be calculated once since each participant contributes data to all three conditions 
```

##### Data visualisation:

```{r}
memory_data_long <- gather(memory_data, Age_group, Score, Age_15:Age_17) # coverts the data to long format
memory_data_long

memory_data_long$Age_group <- recode(memory_data_long$Age_group, "Age_15" = "15 years old",   # changes the factor level names
                                     "Age_16" = "16 year old",
                                     "Age_17" = "17 year old") 
```

```{r}
ggplot(memory_data_long, aes(x=Age_group, y=Score)) + 
  geom_boxplot() + 
  labs(y = "Working memory score", x = "Age group") + # adds a y label which makes it clearer what our outcome measure is
  theme_cowplot() # formats the figure nicely
```

Here, we can see there is very little difference between the medians of the 15 and 16 year old groups. There is a large difference between the 15 and 17 year olds and the 16 and 17 year olds.

#### Performing the Friedman's ANOVA

```{r}
# creates a new dataframe containing all columns except from the "Participant" column 
memory_data_reduced <- memory_data %>% select(-Participant) 
```

Run the model:

```{r}
model2 <- friedman.test(as.matrix(memory_data_reduced)) 
model2
```

The p-value is equal to 0.001 (if we round to three decimal places), indicating there is a significant effect of age group. 

#### Post-hoc tests

```{r}
# requires PMCMRplus library
frdAllPairsConoverTest(memory_data_long$Score, memory_data_long$Age_group, memory_data_long$Participant, p.adjust = "holm")
```
The post-hoc tests revealed a significant difference between the Age_15 and Age_17 timepoints, and the Age_16 and Age_17 timepoints. There is no significant difference between the Age_15 and Age_16 timepoints.

#### Interpretation:

Friedman’s ANOVA revealed that there was a significant effect of age group on working memory score, $x^{2}_{F}$(2) = 14.00, *p* = .001. Post-hoc comparisons were then conducting using the Conover test. P-values were corrected using Bonferroni-Holm. There was a significant difference between performance at 15 year of age (median = 40; range = 10-48) and 17 years of age (median = 66; range = 62-87; *p* = 0.008), and 16 years of age (median = 42; range = 16-66) and 17 years of age (*p* = 0.024). Participants performed significantly better at the 17 year old timepoint relative to the 15 and 16 year old timepoint. No significant difference emerged between the 15 year old and 16 year old timepoints (*p* = 0.490).

## Worksheet:

The answers are in the next section.

### Activity 1: Understanding how the non-parametric tests differ and when to use them

It is really important that you understand which statistical test you should run in different situations. This activity will test your knowledge of the statistical tests you learned during this lecture and {#wilcoxon-rank-sum-signed-rank}.

In each of the following scenario, you are interested in whether the type of chocolate eaten affects feelings of contentment (response = 0-100). For each scenario, think about the following questions:

**Scenario 1: You recruit 20 participants. On day 1, they eat milk chocolate. On day 2, they eat dark chocolate. On day 3, they eat white chocolate.**

a) How would you check whether the assumption of normality is violated for this design?

b) If the assumption of normality is violated, which non-parametric test would you run?

**Scenario 2: You recruit 12 participants and randomly assign them to either a “white chocolate”, “milk chocolate”, or “dark chocolate” group.**

a) How would you check whether the assumption of normality is violated for this design?

b) If the assumption of normality is violated, which non-parametric test would you run?

**Scenario 3: You recruit 7 participants. On day 1, they eat milk chocolate and on day 2, they eat dark chocolate.**

a) How would you check whether the assumption of normality is violated for this design?

b) If the assumption of normality is violated, which non-parametric test would you run?

**Scenario 4: You recruit 10 participants and randomly assign them to either a “white chocolate” or “milk chocolate” group.**

a) How would you check whether the assumption of normality is violated for this design?

b) If the assumption of normality is violated, which non-parametric test would you run?

### Activity 2: Interpreting R output

Interpret the following R output. Part 1 uses an independent groups design, whilst part 2 uses a repeated measures design.

#### Part 1: An independent groups design

You are a developmental researcher interested in whether the books children are exposed to affects their language production (how many words they can say). You recruit 21 2-year-old children and assign them to one of three groups – “Pinocchio”, “Cinderella”, and “Gruffalo”. The children’s parents then read this story every day for three months (i.e. children in the “Gruffalo” group read the Gruffalo every day). You then ask their parents to complete a language production assessment on their child (score = 0-100). 

##### Testing the assumption of normality:

###### Group 1: 
```{r echo = FALSE}
data <- read.csv("l7_worksheet1.csv")

Pinocchio <- data %>% filter(Book == "Pinocchio")

qqnorm(Pinocchio$Words)
qqline(Pinocchio$Words, col = "steelblue")

shapiro.test(Pinocchio$Words)
```

###### Group 2: 
```{r echo = FALSE}
Cinderella <- data %>% filter(Book == "Cinderella")

qqnorm(Cinderella$Words)
qqline(Cinderella$Words, col = "steelblue")

shapiro.test(Cinderella$Words)
```

###### Group 3: 
```{r echo = FALSE}
Gruffalo <- data %>% filter(Book == "Gruffalo")

qqnorm(Gruffalo$Words)
qqline(Gruffalo$Words, col = "steelblue")

shapiro.test(Gruffalo$Words)
```

Is the assumption violated?

##### Interpret the descriptive statistics and the model output

```{r echo = FALSE}
data %>%
  group_by(Book) %>%
  summarise(med_words = median(Words),
            min_words = min(Words),
            max_words = max(Words))

model1 <- kruskal.test(Words ~ Book, data = data)
model1

dunnTest(Words~Book,data=data, method = "holm")
```

What can we conclude? Report in APA format.

#### Part 2: A repeated measures design

You are a researcher interested in whether the number of hours sleep individuals get affects their performance on an attention task (score = 0-100). You recruit nine participants, with all participants taking part in three conditions. In the first condition, participants get 6 hours sleep the night before (6 hours). In the second condition, they get 8 hours sleep the night before (8 hours), and in the third condition, they get 10 hours sleep the night before (10 hours).

##### Testing the assumption of normality:

6 hours condition:

```{r echo = FALSE}
sleep_data <- read.csv("l7_worksheet2.csv")
qqnorm(sleep_data$six_hours)
qqline(sleep_data$six_hours, col = "steelblue")

shapiro.test(sleep_data$six_hours)
```

8 hours condition:

```{r echo = FALSE}
qqnorm(sleep_data$eight_hours)
qqline(sleep_data$eight_hours, col = "steelblue")

shapiro.test(sleep_data$eight_hours)
```

10 hours condition:

```{r echo = FALSE}
qqnorm(sleep_data$ten_hours)
qqline(sleep_data$ten_hours, col = "steelblue")

shapiro.test(sleep_data$ten_hours)
```

Is the assumption violated?

##### Interpret the descriptive statistics and the model output

```{r echo = FALSE}
sleep_data_reduced <- sleep_data %>% select(-Participant)

sleep_data_long <- gather(sleep_data, Condition, Score, six_hours:ten_hours) # coverts the data to long format
sleep_data_long

model2 <- friedman.test(as.matrix(sleep_data_reduced)) # remember this needs to be loaded in as a matrix
model2

frdAllPairsConoverTest(sleep_data_long$Score, sleep_data_long$Condition, sleep_data_long$Participant, p.adjust = "holm")

sleep_data %>%
  summarise(med_six_hours = median(six_hours), med_eight_hours = median(eight_hours), med_ten_hours = median(ten_hours), 
            min_six_hours = min(six_hours), min_eight_hours = min(eight_hours), min_ten_hours = min(ten_hours),
            max_six_hours = max(six_hours), max_eight_hours = max(eight_hours), max_ten_hours = max(ten_hours))
```

What can we conclude? Report in APA format.

## Worksheet answers:

Answers are in purple below.

### Activity 1: Understanding how the non-parametric tests differ and when to use them

**Scenario 1: You recruit 20 participants. On day 1, they eat milk chocolate. On day 2, they eat dark chocolate. On day 3, they eat white chocolate.**

a) How would you check whether the assumption of normality is violated for this design? 

<span style="color:purple">Assess whether the assumption of normality is violated per condition. This can be done using Q-Q plots and the Shapiro-Wilk test</span>

b) If the assumption of normality is violated, which non-parametric test would you run?

<span style="color:purple">Friedman's ANOVA</span>

**Scenario 2: You recruit 12 participants and randomly assign them to either a “white chocolate”, “milk chocolate”, or “dark chocolate” group.**

a) How would you check whether the assumption of normality is violated for this design? 

<span style="color:purple">Assess whether the assumption of normality is violated per group. This can be done using Q-Q plots and the Shapiro-Wilk test.</span>

b) If the assumption of normality is violated, which non-parametric test would you run?

<span style="color:purple">Kruskal-Wallis test</span>

**Scenario 3: You recruit 7 participants. On day 1, they eat milk chocolate and on day 2, they eat dark chocolate.**

a) How would you check whether the assumption of normality is violated for this design? 

<span style="color:purple">Calculate a difference score for each participant (Timepoint 1 – Timepoint 2). Assess whether the assumption of normality is violated for the “difference". This can be done using Q-Q plots and the Shapiro-Wilk test.</span>

b) If the assumption of normality is violated, which non-parametric test would you run?

<span style="color:purple">Wilcoxon signed-rank test</span>

**Scenario 4: You recruit 10 participants and randomly assign them to either a “white chocolate” or “milk chocolate” group.**

a) How would you check whether the assumption of normality is violated for this design? 

<span style="color:purple">Assess whether the assumption of normality is violated per group. This can be done using Q-Q plots and the Shapiro-Wilk test</span>

b) If the assumption of normality is violated, which non-parametric test would you run?

<span style="color:purple">Wilcoxon rank-sum test</span>

### Activity 2: Interpreting R output

#### Part 1: An independent groups design

##### Testing the assumption of normality:

###### Group 1: 
```{r echo = FALSE}
Pinocchio <- data %>% filter(Book == "Pinocchio")

qqnorm(Pinocchio$Words)
qqline(Pinocchio$Words, col = "steelblue")

shapiro.test(Pinocchio$Words)
```

###### Group 2: 
```{r echo = FALSE}
Cinderella <- data %>% filter(Book == "Cinderella")

qqnorm(Cinderella$Words)
qqline(Cinderella$Words, col = "steelblue")

shapiro.test(Cinderella$Words)
```

###### Group 3: 
```{r echo = FALSE}
Gruffalo <- data %>% filter(Book == "Gruffalo")

qqnorm(Gruffalo$Words)
qqline(Gruffalo$Words, col = "steelblue")

shapiro.test(Gruffalo$Words)
```

**Is the assumption violated?**

<span style="color:purple">The Q-Q plot and the Shapiro-Wilk test suggests that the assumption of normality is violated for the Pinocchio group. Data in the Cinderella and Gruffalo group does not appear to violate the assumption.</span>

##### Interpret the descriptive statistics and the model output

```{r echo = FALSE}
data %>%
  group_by(Book) %>%
  summarise(med_words = median(Words),
            min_words = min(Words),
            max_words = max(Words))

model1 <- kruskal.test(Words ~ Book, data = data)
model1

dunnTest(Words~Book,data=data, method = "holm")
```

**What can we conclude? Report in APA format.**

<span style="color:purple">The Kruskal-Wallis test revealed a significant effect of book on the language production score, *H*(2) = 17.85, *p* < .001. Post-hoc comparisons were conducted using Dunn’s test, with p-values corrected using Bonferroni-Holm. There was a significant difference between the Cinderella (median = 16; range = 12-18) and the Gruffalo groups (median = 67; range = 61-69), with participants in the Gruffalo group achieving a significantly higher score (*p* < .001). Participants in the Gruffalo group also achieved a significantly higher score than participants in the Pinocchio group (median = 25; range = 21-58; *p* = .035). No significant difference was observed between the Cinderella and the Pinocchio groups (*p* = .069).</span>

#### Part 2: A repeated measures design

##### Testing the assumption of normality:

6 hours condition:

```{r echo = FALSE}
qqnorm(sleep_data$six_hours)
qqline(sleep_data$six_hours, col = "steelblue")

shapiro.test(sleep_data$six_hours)
```

8 hours condition:

```{r echo = FALSE}
qqnorm(sleep_data$eight_hours)
qqline(sleep_data$eight_hours, col = "steelblue")

shapiro.test(sleep_data$eight_hours)
```

10 hours condition:

```{r echo = FALSE}
qqnorm(sleep_data$ten_hours)
qqline(sleep_data$ten_hours, col = "steelblue")

shapiro.test(sleep_data$ten_hours)
```

**Is the assumption violated?**

<span style="color:purple">Data in the 6 hour condition appears to violate the assumption of normality.</span>

##### Interpret the descriptive statistics and the model output

```{r echo = FALSE}
sleep_data_reduced <- sleep_data %>% select(-Participant)

sleep_data_long <- gather(sleep_data, Condition, Score, six_hours:ten_hours) # coverts the data to long format

model2 <- friedman.test(as.matrix(sleep_data_reduced)) # remember this needs to be loaded in as a matrix
model2

frdAllPairsConoverTest(sleep_data_long$Score, sleep_data_long$Condition, sleep_data_long$Participant, p.adjust = "holm")

sleep_data %>%
  summarise(med_six_hours = median(six_hours), med_eight_hours = median(eight_hours), med_ten_hours = median(ten_hours), 
            min_six_hours = min(six_hours), min_eight_hours = min(eight_hours), min_ten_hours = min(ten_hours),
            max_six_hours = max(six_hours), max_eight_hours = max(eight_hours), max_ten_hours = max(ten_hours))
```

**What can we conclude? Report in APA format.**

<span style="color:purple">A Friedman’s ANOVA revealed a significantly effect of sleep hours on the attention score, $x^{2}_{F}$(2) = 13.56, *p* = .001. Post-hoc comparisons were then conducting using the Conover test, with p-values corrected using Bonferroni-Holm. A significant difference emerged between the 6 hour (median = 54; range = 46-89) and the 10 hour conditions (median = 95; range = 91-99; *p* =.014), with participants performing better in the 10 hour condition. There was also a significant difference between the 8 hour (median = 73; range = 66-81) and the 10 hour conditions (*p* = .015). No significant difference emerged between the 6 hour and 8 hour conditions (*p* = .817).</span>

<!--chapter:end:03-Non-parametric-tests-2.Rmd-->

# Lecture 8 (Binary logistic regression) {#binary-log-regression}

```{r set, include=FALSE}
library(tidyverse) 
library(DescTools)
```
## Lecture

This lecture comprises four parts:

**Part 1: Why do I need to worry about binary logistic regression?**

Part 1 covers why it is important to understand binary logistic regression, and why it is not appropriate to run a linear regression model when the outcome is continuous. It also covers an introduction to binary logistic regression.

Lecture recording:

Slides: 

**Part 2: Odds and odds ratios**

Part 2 introduces the concept of odds and odds ratios, and provides an example of how to calculate odds ratios manually (to aid in understanding about what odds and odds ratios represents).

Lecture recording:

Slides: 

**Part 3: Assumptions of binary logistic regression with one categorical predictor**

Part 3 covers the assumptions of binary logistic regression when you have one categorical predictor.

Lecture recording:

Slides: 

**Part 4: Running a binary logistic regression model (with one categorical predictor) in R**

Part 4 covers how to run a binary logistic regression model with one categorical predictor in R, and how to interpret the output.

Lecture recording:

Slides: 

## Lab preparation

Before the lab, please watch the following video. This walks you through how to run a binary logistic regression model with one categorical predictor in R.

The R markdown script covered in this video can be found here:

## Lab

In the lab, we'll run a binary logistic regression model with one categorical predictor in R.  Please download the following datafile: "reptile_data.csv".

The datasets relate to the following research question:

You are interested in whether the country an individual lives (UK/Australia) predicts reptile ownership (Yes/No). 

In the dataset, the outcome variable (reptile) is coded as “Y” and “N” (where Y = Yes and N = No)

To make sure we should all end up with the same output, set UK as your reference category for the "Country" variable.

1. Work through the following steps:

2. Prepare our data for analysis

3. Explore our data

4. Run the binary logistic regression model

5. Evaluate the model

6. Evaluate the individual predictors

7. Predicted probabilities

8. Interpret the output

## Lab - model script

Here is a model script that produces the answers to the above research question. I use the word 'model' loosely, as you may have used different functions you've learned over the last two years (and that's absolutely fine!). So don't worry if you haven't used the exact same functions as me. You should end up with the same results and interpretation at the end though.

### Binary logistic regression (with one categorical predictor)

```{r}
library(tidyverse) 
library(DescTools)
```

#### Read in the data

This chunk reads in the data.

```{r}
reptile_data <- read.csv("reptile_data.csv")
```

#### Prepare the data for analysis

##### Preparing our outcome variable:

Check the outcome is a numeric variable.

```{r}
str(reptile_data$Reptile)
```

Outcome is a character. Create a numeric variable and check the structure of this new variable:

```{r}
reptile_data$Reptile_numeric <- recode(reptile_data$Reptile, "N" = 0, "Y"= 1) 
str(reptile_data$Reptile_numeric)
```

Now let's view the data to see if this has worked well:

```{r}
view(reptile_data)
```

This chunk of code has worked well - "Reptile_numeric" equals 1 when "Reptile" equals "Y", and "Reptile_numeric"equals 0 when "Reptile" equals "N".

##### Preparing our predictor variable:

I want Country to be a factor with UK as the reference category. I therefore need country to be a factor with "UK" set as the first factor level. This chunk of code checks whether Country is a factor, and checks the order of the factor levels:

```{r}
str(reptile_data$Country)
```

County is a character. The folliwng chunk of code sets Country as factor and makes UK the first factor level. It then runs the "str" function again to checks this has worked well:

```{r}
reptile_data$Country <- factor(reptile_data$Country, c("UK", "Australia"))
str(reptile_data$Country)
```

Country is a factor, with UK is the first factor level. This will therefore be my reference category.

To double check this is true, we can also check using the constrasts function:

```{r}
contrasts(reptile_data$Country)
```

This confirms that UK will be our reference category.

##### Exploring the data:

```{r}
table(reptile_data$Country, reptile_data$Reptile_numeric)
```

From this, we can see that most people in the UK don't own a reptile. Whereas more than 50% of people in Australia do. 

We can also use this table to check for complete separation or quasi-complete separation - we have no cells with 0 so there's no evidence of complete separation or quasi-complete separation.

##### Running the analysis:

The following code runs the model and produces a summary of the output:

```{r}
country_model <- glm(Reptile_numeric ~ Country, data = reptile_data, family=binomial())

summary(country_model)

```

##### Evaluating the model:

###### Assessing the fit of the model:

This chunk of code produces the model chi square, the degrees of freedom and the p-value:

```{r}
country_model_chi <- country_model$null.deviance - country_model$deviance # produces model chi square
country_model_chi_df <- country_model$df.null - country_model$df.residual # produces model degrees of freedom
model_p <- 1 - pchisq(country_model_chi, country_model_chi_df) # produces model p-value


country_model_chi # chi square
country_model_chi_df # degrees of freedom
model_p # p-value
```

This indicates that adding country to our model significantly improved the fit, compared to the null model containing intercept only ($x^{2}$(1) = 5.49, *p* = .019).

##### Producing Pseudo $R^{2}

```{r}
PseudoR2(country_model, which = "all")
```

McFadden Pseudo $R^{2} = 0.12
CoxSnell Pseudo $R^{2} = 0.15
Nagelkerke Pseudo $R^{2} = 0.20

#### Evaluating the individual predictors:

##### Odds ratios:

```{r}
country_model_exponentiated <- exp(country_model$coefficients)
country_model_exponentiated
```

The odds of owning a reptile are higher for individuals who live in Australia relative to individuals who live in the UK (odds ratio = 5.63).

##### Confidence intervals around the odds ratio:

```{r}
country_model_odds_confidence_intervals <- exp(confint(country_model))
country_model_odds_confidence_intervals
```

The true odds ratio in the population is likely to be somewhere between 1.32 and 28.26. As the confidence intervals doesn't cross 1, the p-value for CountryAustralia is significant. This can be confirmed by examining the output of summary(country_model) above, in which the p-value is .025.

#### Predicted probabilities

```{r}
reptile_data$pred_prob <- fitted(country_model)
reptile_data$pred_prob
```

#### Overall interpretation of our model:

A binary logistic regression was conducted to examine whether country (UK/Australia) significantly predicted reptile ownership (yes/no). UK was set as the reference category for the country variable. The model predicted reptile ownership significantly better than the intercept-only model ($x^{2}(1) = 5.49, *p* = .019; McFadden Pseudo $R^{2} = 0.12, CoxSnell Pseudo $R^{2} = 0.15, Nagelkerke Pseudo $R^{2} = 0.20). Individuals who live in Australia had significantly higher odds of owning a reptile relative to individuals who live in the UK (Odds ratio = 5.63, 95% confidence interval = 1.32-28.26, *p* = .025).

## Worksheet:

The answers are in the next section.

### Activity 1: Calculating odds ratios manually

Activity 1 will involve work with the following data. You are a researcher interested in whether being excited (yes/no) predicts whether an individual passes their driving test (yes/no). Here is a table of frequencies.

```{r echo = FALSE} 
l8_w1 <- read.csv("l8_worksheet1.csv")
l8_w1_table <- table(l8_w1$Passed, l8_w1$Excited)
colnames(l8_w1_table) = c("Excited - No", "Excited - Yes")
rownames(l8_w1_table) = c("Passed - No", "Passed - Yes") 

l8_w1_table
```

**What are the odds of passing the driving test in the “Excited – Yes” group?**

**What are the odds of passing the driving test in the “Excited – No” group?**

**What is the odds ratio (where “Excited – No” is the original odds)?**
 
**What does this odds ratio mean?**

**Is there evidence of quasi-complete separation or complete separation here? Give a reason for your answer.**

### Activity 2: Interpreting R output

Activity 2 examines the following research question. You are a researcher interested in whether being rich (yes/no) predicts whether an individual owns a Tesla. Here is a table of frequencies:

```{r echo = FALSE} 
l8_w2 <- read.csv("l8_worksheet2.csv")
l8_w2_table <- table(l8_w2$Rich, l8_w2$Tesla)
colnames(l8_w2_table) = c("Tesla - Yes", "Tesla - No")
rownames(l8_w2_table) = c("Rich - No", "Rich - Yes") 

l8_w2_table
```

You analyse this data in R and the output of your model is below. For the outcome, you set “0” as “Has a Tesla – No” and “1” as “Has a Tesla – Yes” 

#### Model output

Here is the model output:

```{r}
l8_w2$tesla_numeric <- recode(l8_w2$Tesla, "No" = 0, "Yes"= 1) 
tesla_model <- glm(tesla_numeric ~ Rich, data = l8_w2, family=binomial())
summary(tesla_model)
```

#### Evaluating the model output

You run some code to produce the model’s chi-square statistic, the degrees of freedom and the p-value. These are displayed below:

Chi square = 8.2
Degrees of freedom = 1
P-value = 0.004

**What do these values indicate?**

#### Evaluating Pseudo R2

```{r}
PseudoR2(tesla_model, which = "all")
```

**Which Pseudo R2 values might you report (based on the lecture)?**

**What is the value of these Pseudo R2s?**

#### Evaluating the individual predictors

Looking back at the summary output, consider the following questions:

**What is the reference category for the predictor “Rich”?**

**What does the Intercept Estimate represent?**

**What does the RichYes Estimate represent?**

##### Exponentiating the estimates:

```{r}
tesla_model_exponentiated <- exp(tesla_model$coefficients)
tesla_model_exponentiated
```

**What does the Intercept represent?**

**What does the RichYes value represent?**

**Can you interpret the  RichYes value?**

##### Confidence intervals:

```{r}
tesla_model_odds_confidence_intervals <- exp(confint(tesla_model))
tesla_model_odds_confidence_intervals
```

**What does the RichYes 95% confidence intervals represent?**

**From the p-value in the summary table for the RichYes row, what can you conclude?**

**Is there another output we could look at to reach the same broad conclusion (regarding whether the predictor significantly predicts the outcome)?**

## Worksheet - answers

### Activity 1: Calculating odds ratios manually

```{r echo = FALSE} 
l8_w1 <- read.csv("l8_worksheet1.csv")
l8_w1_table <- table(l8_w1$Passed, l8_w1$Excited)
colnames(l8_w1_table) = c("Excited - No", "Excited - Yes")
rownames(l8_w1_table) = c("Passed - No", "Passed - Yes") 

l8_w1_table
```

**What are the odds of passing the driving test in the “Excited – Yes” group?**

<span style="color:purple">The probability of individuals who are excited (Excited – Yes) passing the driving test:</span>

<span style="color:purple">14/26 = 0.5384615385</span>

<span style="color:purple">14 is the number of participants who were excited and passed the driving test. </span>

<span style="color:purple">26 is the total number of individuals who responded “Excited – Yes” (14+12)</span>

<span style="color:purple">The probability of individuals who are excited (Excited – Yes) not passing the driving test: </span>

<span style="color:purple">12/26 = 0.4615384615</span>

<span style="color:purple">12 is the number of participants who were excited and did not pass the driving test.</span> 

<span style="color:purple">26 is the total number of individuals who responded “Excited – Yes” (14+12)</span>

<span style="color:purple">The odds of individuals who are excited passing the driving test:</span>

<span style="color:purple">0.5384615385 / 0.4615384615 = 1.1666666668</span>

**What are the odds of passing the driving test in the “Excited – No” group?**

<span style="color:purple">The probability of individuals who are not excited (Excited – No) passing the driving test:</span>

<span style="color:purple">8/37 = 0.216216216</span>

<span style="color:purple">8 is the number of participants who were not excited and passed the driving test. </span>

<span style="color:purple">37 is the total number of individuals who responded “Excited – No” (8+29)</span>

<span style="color:purple">The probability of individuals who are excited (Excited - No) not passing the driving test: </span>

<span style="color:purple">29/37 = 0.783783783</span>

<span style="color:purple">29 is the number of participants who were not excited and did not pass the driving test. </span>

<span style="color:purple">37 is the total number of individuals who responded “Excited – No” (8+29)</span>

<span style="color:purple">The odds of individuals who are not excited passing the driving test:</span>

<span style="color:purple">0.216216216 / 0.783783783 = 0.275862069</span>

**What is the odds ratio (where “Excited – No” is the original odds)?**

<span style="color:purple">1.1666666668  / 0.275862069 = 4.23</span>

<span style="color:purple">The odds ratio = 4.23</span>
 
**What does this odds ratio mean?**

<span style="color:purple">Individuals who were excited had a 4.23x higher odds of passing the driving test relative to individuals who were not excited.</span>

**Is there evidence of quasi-complete separation or complete separation here? Give a reason for your answer.**

<span style="color:purple">No – all cells have quite a few observations so there is no evidence of quasi-complete separation or complete separation.</span>

### Activity 2: Interpreting R output

Activity 2 examines the following research question. You are a researcher interested in whether being rich (yes/no) predicts whether an individual owns a Tesla. Here is a table of frequencies:

```{r echo = FALSE} 
l8_w2 <- read.csv("l8_worksheet2.csv")
l8_w2_table <- table(l8_w2$Rich, l8_w2$Tesla)
colnames(l8_w2_table) = c("Tesla - Yes", "Tesla - No")
rownames(l8_w2_table) = c("Rich - No", "Rich - Yes") 

l8_w2_table
```

You analyse this data in R and the output of your model is below. For the outcome, you set “0” as “Has a Tesla – No” and “1” as “Has a Tesla – Yes” 

#### Model output

Here is the model output:

```{r}
l8_w2$tesla_numeric <- recode(l8_w2$Tesla, "No" = 0, "Yes"= 1) 
tesla_model <- glm(tesla_numeric ~ Rich, data = l8_w2, family=binomial())
summary(tesla_model)
```

#### Evaluating the model output

You run some code to produce the model’s chi-square statistic, the degrees of freedom and the p-value. These are displayed below:

Chi square = 8.2
Degrees of freedom = 1
P-value = 0.004

**What do these values indicate?**

<span style="color:purple">$x^{2}$(1) = 8.20, *p* = .004.

<span style="color:purple">This indicates that adding the “Rich” variable to our model significantly improved the fit, compared to the null model containing intercept only</span>

#### Evaluating Pseudo R2

```{r}
PseudoR2(tesla_model, which = "all")
```

**Which Pseudo R2 values might you report (based on the lecture)?**

<span style="color:purple">McFadden, CoxSnell and Nagelkerke</span>

**What is the value of these Pseudo R2s?**

<span style="color:purple">McFadden = 0.19
CoxSnell = 0.16
Nagelkerke = 0.27</span>

#### Evaluating the individual predictors

Looking back at the summary output, consider the following questions:

**What is the reference category for the predictor “Rich”?**

<span style="color:purple">“No” is our reference category for the Rich variable</span>

**What does the Intercept Estimate represent?**

<span style="color:purple">The log odds of someone with a Rich value of “No” having a tesla</span>

**What does the RichYes Estimate represent?**

<span style="color:purple">The change in the log odds of having a tesla value of “Yes” when going from the reference category (RichNo) to RichYes</span>

##### Exponentiating the estimates:

```{r}
tesla_model_exponentiated <- exp(tesla_model$coefficients)
tesla_model_exponentiated
```

**What does the Intercept represent?**

<span style="color:purple">The odds of having a tesla for individuals who are not rich</span>

**What does the RichYes value represent?**

<span style="color:purple">The change in odds (i.e. the odds ratio) of having a tesla (i.e. tesla = yes) when going from RichNo to RichYes</span>

**Can you interprert the RichYes value?**

<span style="color:purple">The odds of having a tesla are 11.33x higher if you are rich than if you are not rich</span>

##### Confidence intervals:

```{r}
tesla_model_odds_confidence_intervals <- exp(confint(tesla_model))
tesla_model_odds_confidence_intervals
```

**What does the RichYes 95% confidence intervals represent?**

<span style="color:purple">The 95% confidence around the odds ratio (for the comparison between RichNo to RichYes).</span>

**From the p-value in the summary table for the RichYes row, what can you conclude?**

<span style="color:purple">Whether an individual is rich (yes/no) significantly predicts whether they have a tesla (yes/no; *p* = .005)</span>

**Is there another output we could look at to reach the same broad conclusion (regarding whether the predictor significantly predicts the outcome)?**

<span style="color:purple">Yes, you could also look at the output for the 95% confidence interval around the odds ratio. As both the lower and upper bound of the confidence interval are above 1, this indicates that the p-value would be significant - whether an individual is rich (yes/no) significantly predicts whether they have a tesla (yes/no)</span>

<!--chapter:end:04-Binary-logistic-regression.Rmd-->

# Lecture 9 (Extending binary logistic regression) {#extending-binary-regression}

```{r set, include=FALSE}
library(car)
library(DescTools) 
library(tidyverse)
library(MASS)
library(brant)
library(kableExtra)
```
## Lecture

This lecture extends the content taught in {#extending-binary-regression} to three new contexts: binary logistic regression with different types of predictors, multiple binary logistic regression, and proportional odds models.

**Part 1: Binary logistic regression with different types of predictors**

This part of the lecture covers binary logistic regression with one categorical predictor with three or more levels and binary logistic regression with one continuous predictor.

Lecture recording:

Slides: 

**Part 2: Multiple binary logistic regression**

Part 2 covers multiple binary logistic regression: binary logistic regression with multiple predictor variables (i.e. more than one predictor). 

Lecture recording:

Slides: 

**Part 3: Proportional odds models**

Part 3 covers proportional odds models - a type of model that could be considered if the outcome is ordinal (has ordered levels).

Lecture recording:

Slides: 


## Lab preparation

Before the lab, please watch the following video. This walks you through how to run a proportional odds model. 

Please also take a look at this R markdown file. This covers how to run a multiple binary logistic regression model and a proportional odds model:  

## Lab

In the lab, we'll run a multiple binary logistic regression model and a proportional odds model.  Please download the following zip file which contains two datasets: "measles_data.csv" and "academic_data.csv". 

The datasets relate to the following research questions:

**1. Academic dataset**

You are interested in factors that predict academic achievement in mathematics. Children’s academic achievement can be rated as below expected, at expected or above expected. 

The predictors you are interested in are:
* Number if hours spent revising (continuous)
* Likes school (Yes/no)
* Favourite subject (Maths, English or Science)

To make sure we should all end up with the same output:
*Set the reference category for Likes school as “No”
*Set the reference category for Favourite subject as “Maths”

**2. Measles dataset**

You work in a nursery. In the nursery, there has been an outbreak of measles. You are interested in factors that predict whether a child in your nursery will have measles (yes/no). 

The predictors you are interested in are:
* Number of hours spent at nursery weekly (continuous)
* Has siblings(Yes/no)
* Vaccinated against measles (Yes/no)

For the categorical predictors:
* Set the reference category for Siblings as “No”
* Set the reference category for Vaccinated as “No”

For the outcome (measles – yes/no):
* Set No as 0, and Yes as 1

## Lab - model script

Here is a model script that produces the answers to the above research questions. I use the word 'model' loosely, as you may have used different functions you've learned over the last two years (and that's absolutely fine!). So don't worry if you haven't used the exact same functions as me. You should end up with the same results and interpretation at the end though.

```{r }
library(car)
library(DescTools) 
library(tidyverse)
library(MASS)
library(brant)


options(scipen = 999) # shows numeric values rather than scientific notations in the output. 
```

### Proportional odds model:

#### Read in the data

This chunk reads in the data.

```{r}
academic_data <- read.csv("academic_data.csv")
```

#### Prepare the data for analysis

First, let's check the structure of the data. The variables should have the following formats:

* Number_hours_revising = needs to be a numeric or integer 
* Favourite subject = Factor, with "Maths" as the first factor level (so all other subjects are compared to maths)
* Likes school = Factor, with "No" as the first factor level (so the odds ratio will tell you the odds when going from does not like school to likes school)
* Academic_performance = needs to be an ordered factor, equal to Below < Expected < Above 

```{r}
str(academic_data)
```

Number_hours_revising is as we need it. We need to change the favourite subject variable and likes school variable to factors (where "Maths" is the first factor level of favourite subject and "No" is the first factor level of Likes school. The struture of academic performance so that this is an on ordered factor. 

```{r}
academic_data$Favourite_subject <- factor(academic_data$Favourite_subject, c("Maths", "English", "Science"))
academic_data$Likes_school <- factor(academic_data$Likes_school, c("No", "Yes"))
academic_data$Academic_performance <- ordered(academic_data$Academic_performance,levels = c("Below", "Expected", "Above"))
```

Now let's check the structure of our dataframe again:

```{r}
str(academic_data)
```

All of the variables are now in the correct format.

To double check this, we can produce contrasts for categorical predictors. If "Maths" is the reference category of Favourite_subject, we should expect all values on the "Maths" row to be 0. 

```{r}
contrasts(academic_data$Favourite_subject)
```

"Maths" is our reference category. Let's now repeat this for the Likes_school variable. If "No" is the first factor level for Likes_school, we should expect No to have 0 a next to it. 

```{r}
contrasts(academic_data$Likes_school)
```

No will be the reference category for Likes_school. 

We only check contrasts for categorical predictors (to check which level will be our reference category), so we don't need to do this for Number_hours_revising, as this variable is continuous.

##### Exploring the data:

When we have categorical predictors, we can produce a table to look at the number of participants who have combinination of predictor level and each outcome. This allow us to understand the data and look for evidence of quasi-complete separation or complete separation. 

##### Favourite subject:

```{r}
table(academic_data$Favourite_subject, academic_data$Academic_performance)
```

No evidence of separation issues.

##### Likes school:

```{r}
table(academic_data$Likes_school, academic_data$Academic_performance)
```

No evidence of separation issues.

We can look for separation issues for our continuous variable by looking to see whether there are any error messages when we run the model, and by looking at whether the standard errors are very large.

##### Running the analysis:

The following code runs the model and produces a summary of the output:

```{r}
academic_model <- polr(formula = Academic_performance ~ Favourite_subject + Number_hours_revising + Likes_school, data = academic_data, Hess = TRUE)

summary(academic_model)
```

No warning messages, suggesting we don't have quasi-complete separation or complete separation. The estimates and standard errors are also quite low, so this is further evidence of no separation issues.

As we can see from this output, there are no-p-values. The following chunk of code calculates the p-values and binds them with the information about the individual predictors above. 

```{r}
coefficients <- summary(academic_model)$coefficients

p_value <- (1 - pnorm(abs(coefficients[ ,"t value"]), 0, 1))*2

coefficients_with_p <- cbind(coefficients, p_value)

coefficients_with_p
```

##### Evaluating the model:

##### Assessing the fit of the model:

This chunk of code produces an intercept-only model (a model containing only the intercept - i.e. no predictors) and compares these models.

```{r}
intercept_model <- polr(formula = Academic_performance ~ 1, data = academic_data, Hess = TRUE)

anova(academic_model, intercept_model)
```

Adding the Favourite_subject, Number_hours_revising and Likes_school variables to our model significantly improved the fit, compared to the null model containing intercept only ($x^{2}(4) = 23.09, *p* < .001).

##### Producing Pseudo R2s

```{r}
PseudoR2(academic_model, which = "all")
```

McFadden = 0.14
CoxSnell = 0.25
Nagelkerke = 0.29

##### Evaluating the individual predictors:

##### Odds ratios:

```{r}
academic_model_exponentiated <- exp(academic_model$coefficients)
academic_model_exponentiated
```

- 0.43 = The change in the odds (i.e. the odds ratio) of having higher academic achievement (e.g. "above expected" vs "expected" or "below expected") when going from Favourite_subjectMaths to Favourite_subjectEnglish. The odds of having higher academic achievement is lower for individuals whose favourite subject is English relative to Maths (odds ratio = 0.43), when holding other variables constant

- 0.99 = The change in the odds (i.e. the odds ratio) of having higher academic achievement (e.g. "above expected" vs "expected" or "below expected") when going from Favourite_subjectMaths to Favourite_subjectScience. The odds of having higher academic achievement is lower for individuals whose favourite subject is Science relative to Maths (odds ratio = 0.99), when holding other variables constant

- 1.09 = The change in the odds (i.e. the odds ratio) of having higher academic achievement (e.g. "above expected" vs "expected" or "below expected") with a one unit increase in Number_hours_revising. A one unit increase in the number of hours revising was associated with higher odds of having higher academic achievement (odds ratio = 0.45), when holding other variables constant

- 9.29 = The change in the odds (i.e. the odds ratio) of having higher academic achievement (e.g. "above expected" vs "expected" or "below expected") when going from Likes_schoolNo to Likes_schoolYes. The odds of having higher academic achievement is higher in individuals who like school than individuals who do not (odds ratio = 9.29), when holding other variables constant

But are these predictors/comparisons significant?!

##### Confidence intervals around odds ratios:

```{r}
academic_model_odds_confidence_intervals <- exp(confint(academic_model))
academic_model_odds_confidence_intervals
```

The confidence interval for the Likes school row does not include 1 (both the lower and upper bound are above 1). This means these comparison should be significant if we look at the model output. The 95% odds ratio confidence interval for the other rows do cross 1, indicating that these comparisons should not be significant. Looking back at the p-values we calculated confirms this. 

##### Predicted probabilities:

```{r}
pred_probs <- fitted(academic_model)
academic_pred_probs <- cbind(academic_data, pred_probs)
```

##### Checking assumptions:

###### Linearity of the logit:

The following code produces a new variable in the dataframe called "log_Number_hours_revising_int", equal to log of hours free time multiplied by hours free time. A model is then run including all of the original variables plus the new log_Number_hours_revising_int variable. If log_Number_hours_revising_int is significant, the assumption of the linearity of the logit has been violated. We should not interpret the other variables in this model!

```{r}
academic_data$log_Number_hours_revising_int <- log(academic_data$Number_hours_revising)*academic_data$Number_hours_revising

model2 <- polr(formula = Academic_performance ~ Number_hours_revising + Likes_school + Favourite_subject + log_Number_hours_revising_int, data = academic_data, Hess = TRUE)

summary(model2)
```

Produce p-values: 

```{r}
coefficients_model2 <- summary(model2)$coefficients

p_value_model2 <- (1 - pnorm(abs(coefficients_model2[ ,"t value"]), 0, 1))*2

coefficients_model2_plus_p <- cbind(coefficients_model2, p_value_model2)

coefficients_model2_plus_p
```

log_Number_hours_revising_int is not significant (p = .302) - the assumption has not been violated.

###### Multicollinearity:

```{r}
vif(academic_model)
```

GVIF is outputted as one of our variables has three or more levels (Favourite_subject). We should interpret the rows in the last column (GVIF^(1/(2*Df))). All values are below 3.16 indicating no evidence of multicollinearity. 

##### Proportional odds assumption:

```{r}
brant(academic_model)
```

None of the p-values are significant - the proportional odds assumption is not violated.

#### Overall interpretation of our model:

A proportional odds model was conducted to examine factors that predict academic achievement (below expected, at expected, above expected) in mathematics. The predictors considered were: Likes school (yes/no), Favourite subject (Maths, English, Science), and Number_hours_revising (continuous). The model predicted academic achievement significantly better than the intercept-only model ($x^{2}(4) = 23.09, *p* < .001; McFadden Pseudo $R^{2} = 0.14, CoxSnell Pseudo $R^{2} = 0.25, Nagelkerke Pseudo $R^{2} = 0.29). Examination of the individual predictors revealed that individuals who liked school had higher odds of having higher academic achievement relative to individuals who did not like school (odds ratio = 9.29, 95% confidence interval = 3.24-29.34, *p* < .001) when holding the other variables constant. None of the other predictors were significant.  

Note in this paragraph above, I only discussed comparisons/continuous variables that were significant. You could discuss the non-significant ones in text too (this is often a matter of personal preference). If you do not discuss the non-significant ones in the paragraph, you should make sure to include them in the table of the regression output (see the example in the Lecture 8 slides)

### Multiple binary logistic regression:

#### Read in the data

This chunk reads in the data.

```{r}
measles_data <- read.csv("measles_data.csv")
```

#### Prepare the data for analysis

Before we run the binary logistic regression. We first need to check the structure of the dataframe. 

The data needs to be in the following format:
* Hours_attend = numeric or integer
* Siblings = Factor, with "No" as the first factor level
* Vaccinated = Factor, with "No" as the first factor level
* Measles = numeric, with no coded as 0 and yes coded as 1

```{r}
str(measles_data)
```

Hours_attend is an integer variable. Siblings and Vaccinated are characters. These need converting to factors, with "No" set as the first factor level. Measles needs to be convered to a numeric variable.

```{r}
measles_data$Siblings <- factor(measles_data$Siblings, c("No", "Yes"))
measles_data$Vaccinated <- factor(measles_data$Vaccinated, c("No", "Yes"))
measles_data$Measles_numeric <- recode(measles_data$Measles, "No" = 0, "Yes"= 1) 
```

Now let' check the structure of our dataframe again:

```{r}
str(measles_data)
```

We see we have a new variable "Measles_numeric" that is a numeric variable. I've also checked the dataframe to confirm that this has worked properly (i.e. that "Measles_numeric" equals 1 when "Measles" equals "Yes", and "Measles_no" should equals 0 when "Measles" equals "No". 

##### Confirming by checking contrasts:

To confirm that No will be my reference category for Siblings and Vaccinated, I can check the contrasts.

```{r}
contrasts(measles_data$Siblings)
```

```{r}
contrasts(measles_data$Vaccinated)
```

This confirms that no will be the reference category for both Siblings and Vaccinated.

##### Exploring the data:

When we have categorical predictors, we can produce a table to look at the number of participants who have each predictor level and each outcome. This can allow us to understand the data a little better, and also allows us to check for quasi-complete separation or complete separation. 

##### Siblings:

```{r}
table(measles_data$Siblings, measles_data$Measles_numeric)
```

We have no evidence of complete separation or quasi-complete separation for Siblings.

##### Vaccinated:

```{r}
table(measles_data$Vaccinated, measles_data$Measles_numeric)
```

No evidence of complete separation or quasi-complete separation for Vaccinated.

##### Running the analysis:

The following code runs the model and produces a summary of the output:

```{r}
measles_mod <- glm(Measles_numeric ~ Hours_attend + Siblings + Vaccinated, data = measles_data, family=binomial())

summary(measles_mod)

```

No convergence issues or other warning messages. Standard errors are not very large, suggesting there are no separation issues for the hours_attend variable.

Before we evaluate the individual predictors, let's assess the overall fit of the model

##### Evaluating the model:

##### Assessing the fit of the model:
This chunk of code produces the model chi square, the degrees of freedom and the p-value:

```{r}
measles_model_chi <- measles_mod$null.deviance - measles_mod$deviance # produces model chi square
measles_model_chi_df <- measles_mod$df.null - measles_mod$df.residual # produces model degrees of freedom
measles_model_p <- 1 - pchisq(measles_model_chi, measles_model_chi_df) # produces model p-value

measles_model_chi # chi square
measles_model_chi_df # degrees of freedom
measles_model_p # p-value
```

Adding the hours attended, siblings and vaccinated variables to the model significantly improved the fit, compared to the null model containing intercept only ($x^{2}(3) = 19.03, *p* < .001).

##### Producing Pseudo R2s

```{r}
PseudoR2(measles_mod, which = "all")
```

McFadden = 0.29
CoxSnell = 0.27
Nagelkerke = 0.41

##### Evaluating the individual predictors:

##### Odds ratios:

```{r}
measles_mod_exponentiated <- exp(measles_mod$coefficients)
measles_mod_exponentiated
```

- 1.20 = The change in the odds (i.e. the odds ratio) of having measles (i.e. measles = yes) with a one unit increase in hours attended nursery. This indicates that a one unit increase in the hours attended nursery increases the odds of having measles (odds ratio = 1.20), when holding the other variables constant

- 0.66 = The change in the odds (i.e. the odds ratio) of having measles (i.e. measles = yes) when going from SiblingsNo to SiblingsYes. Individuals who has siblings had lower odds of having measles relative to individuals who did not (odds ratio = 0.66), when holding other variables constant

- 0.14 = The change in the odds (i.e. the odds ratio) of having measles (i.e. measles = yes) when going from VaccinatedNo to VaccinatedYes. Individuals who had been vaccinated had lower odds of having measles relative to individuals who had not been vaccinated (odds ratio = 0.14), when holding other variables constant

We need to look if these variables are significant predictors though. First, let's have a look at the confidence intervals around the odds ratios.


##### Confidence intervals around odds ratios:

```{r}
measles_mod_odds_confidence_intervals <- exp(confint(measles_mod))
measles_mod_odds_confidence_intervals
```

The confidence interval for the Hours_attend row and the vaccinatedYes row do not cross 1. This means these comparison should be significant if we look at the model output. Looking at the model output above confirms this: *p* for Hours_attend = .004. *p* for Vaccinated = .018.

##### Predicted probabilities:

```{r}
measles_data$model_pred_probs <- fitted(measles_mod)
```

##### Checking the assumptions:

###### Linearity of the logit:

We need to check this for the hours attend variable.

```{r}
measles_data$log_Hours_attend_int <- log(measles_data$Hours_attend)*measles_data$Hours_attend

model2 <- glm(Measles_numeric ~ Hours_attend + Siblings + Vaccinated + log_Hours_attend_int, data = measles_data, family=binomial())

summary(model2)
```

log_Hours_attend_int is not significant - the assumption has not been violated.

###### No multicollinearity:

```{r}
vif(measles_mod)
```

VIF values - all values are below 10 - there is no evidence of multicollinearity.

#### Overall interpretation of our model:

A binary logistic regression was conducted to examine factors that predict whether a child has measles (yes/no). The predictors entered into the model were: the number of hours a child attends nursery (continuous), whether they have siblings (yes/no) and whether they have been vaccinated against measles (yes/no). The model predicted measles diagnosis significantly better than the intercept-only model ($x^{2}(3) = 19.03, *p* < .001; McFadden Pseudo $R^{2} = 0.29, CoxSnell Pseudo $R^{2} = 0.27, Nagelkerke Pseudo $R^{2} = 0.41). When holding the other variables constant, individuals who were vaccinated had significantly lower odds of having measles relative to individuals who were not vaccinated (Odds ratio (OR) = 0.14; 95% confidence interval around the odds ratio = 0.02-0.69, *p* = .018). A one unit increase in the number of hours the child attended nursery increased the odds of having measles (i.e. measles = yes) (odds ratio = 1.20, 95% confidence interval around the odds ratio = 1.07-1.38; *p* = .004) when holding the other variables constant. Whether or not the child had siblings did not predict whether a child had measles (*p* = .644). 

This should be accompanied by a table of the regression output, including rows for each comparison (see the example in the Lecture 8 slides)

## Worksheet:

The answers are in the next section.

### Activity 1: Interpreting odds ratios from multiple binary logistic regression

Imagine you are interested in examining factors that predict whether an individual has a dog (yes/no). The variables you are interested in are: has children (yes/no), working pattern (full-time, part-time, unemployed), and number of pets previously (continuous). You code dog into a numeric variable where 0 = No and 1 = Yes. You set “No” as the reference category for “has children” and “unemployed” as the reference category for working pattern. Below are the odds ratios and 95% confidence intervals around the odds ratio that you obtain.

```{r echo=FALSE}
variable_name <- c("Has_childrenYes", "Working_patternFull-time", "Working_patternPart-time", "Num_previous_pets")
odds_ratio <- c(3.67, 6.85, 3.12, 0.45)
lower_ci <- c(2.14, 1.34, 0.67, 0.23)
upper_ci <- c(5.64, 14.67, 1.35, 0.67)
l9_w1_tab <- data.frame(variable_name, odds_ratio, lower_ci, upper_ci)
kable(l9_w1_tab, booktabs = TRUE, align=rep('c', 4), col.names = c("",
                 "Odds ratio",
                 "Lower confidence interval bound",
                 "Upper confidence interval bound")) %>%
  kable_styling(position = "center")
  
```

**Can you interpert the odds ratios?**

**Which rows would be significant if you looked at the p-values and why?**

### Activity 2: Interpreting odds ratios from a proportional odds model

Imagine you are interested in examining factors that predict severity of a disease (mild, moderate or severe). The variables you are interested in are: pre-existing health condition (yes/no), smokes (yes/no), and number of units of alcohol consumed weekly (continuous). You code disease severity into an ordered factor (mild < moderate < severe). You set “No” as the reference category for “pre-existing health condition” and “smoking”. Below are the odds ratios and confidence intervals you obtain.

```{r echo=FALSE}
variable_name <- c("Pre-existing_healthYes", "SmokesYes", "Num_alcohol_units")
odds_ratio <- c(2.31, 1.45, 1.12)
lower_ci <- c(1.45, 0.89, 1.02)
upper_ci <- c(4.56, 4.56, 1.45)
l9_w1_tab <- data.frame(variable_name, odds_ratio, lower_ci, upper_ci)
kable(l9_w1_tab, booktabs = TRUE, align=rep('c', 4), col.names = c("",
                 "Odds ratio",
                 "Lower confidence interval bound",
                 "Upper confidence interval bound")) %>%
  kable_styling(position = "center")
  
```

**Can you interpret the odds ratios?**

**Which rows would be significant if you looked at the p-values and why?**

## Worksheet answers

### Activity 1: Interpreting odds ratios from multiple binary logistic regression

```{r echo=FALSE}
variable_name <- c("Has_childrenYes", "Working_patternFull-time", "Working_patternPart-time", "Num_previous_pets")
odds_ratio <- c(3.67, 6.85, 3.12, 0.45)
lower_ci <- c(2.14, 1.34, 0.67, 0.23)
upper_ci <- c(5.64, 14.67, 1.35, 0.67)
l9_w1_tab <- data.frame(variable_name, odds_ratio, lower_ci, upper_ci)
kable(l9_w1_tab, booktabs = TRUE, align=rep('c', 4), col.names = c("",
                 "Odds ratio",
                 "Lower confidence interval bound",
                 "Upper confidence interval bound")) %>%
  kable_styling(position = "center")
  
```

**Can you interpret the odds ratios?**

You could interpret the odds ratios in two ways:

**Way one:**

<span style="color:purple">Individuals who had children had higher odds of having a dog relative to individuals who did not have children (odds ratio = 3.67, 95% confidence interval = 2.14-5.64) when holding other variables constant</span>

<span style="color:purple">Individuals who worked full time had had higher odds of having a dog relative to individuals who were unemployed (odds ratio = 6.85, 95% confidence interval = 1.34-14.67) when holding other variables constant</span>

<span style="color:purple">Individuals who worked part-time had higher odds of having a dog relative to individuals who were unemployed (odds ratio = 3.12, 95% confidence interval = 0.67-1.35) when holding other variables constant</span>

<span style="color:purple">A one unit increase in the number of previous pets was associated with lower odds of currently having a dog (odds ratio = 0.45, 95% confidence interval = 0.23-0.67) when holding other variables constant</span>

**Way two:**

<span style="color:purple">Individuals who had children had 3.67x higher odds of having a dog relative to individuals who did not have children (95% confidence interval = 2.14-5.64), when holding other variables constant</span>

<span style="color:purple">Individuals who worked full time had had 6.85x higher odds of having a dog relative to individuals who were unemployed (95% confidence interval = 1.34-14.67), when holding other variables constant</span>

<span style="color:purple">Individuals who worked part-time had 3.12x higher odds of having a dog relative to individuals who were unemployed (95% confidence interval = 0.67-1.35)</span>

<span style="color:purple">A one unit increase in the number of previous pets was associated with a 0.45x higher odds (i.e. lower odds) of having a dog (odds ratio = 0.45, 95% confidence interval = 0.23-0.67), when holding other variables constant</span>

**Which rows would be significant if you looked at the p-values and why?**

<span style="color:purple">*	Has_childrenYes</span>

<span style="color:purple">*	Working_patternFull-time</span>

<span style="color:purple">*	Num_previous_pets</span>

<span style="color:purple">The 95% confidence interval around the odds ratio does not cross 1 for these comparisons (i.e. both the upper and the lower bound are higher than 1 OR both the upper and the lower bound are lower than 1). For Working_patternPart-time, the 95% confidence interval crosses 1 (i.e. the lower confidence interval bound is below 1 and the higher confidence interval bound is above 1). This means when we look at the output, the p-value for Working_patternPart-time will be above 0.05 (i.e. not significant).</span>

### Activity 2: Interpreting odds ratios from a proportional odds model

```{r echo=FALSE}
variable_name <- c("Pre-existing_healthYes", "SmokesYes", "Num_alcohol_units")
odds_ratio <- c(2.31, 1.45, 1.12)
lower_ci <- c(1.45, 0.89, 1.02)
upper_ci <- c(4.56, 4.56, 1.45)
l9_w1_tab <- data.frame(variable_name, odds_ratio, lower_ci, upper_ci)
kable(l9_w1_tab, booktabs = TRUE, align=rep('c', 4), col.names = c("",
                 "Odds ratio",
                 "Lower confidence interval bound",
                 "Upper confidence interval bound")) %>%
  kable_styling(position = "center")
  
```

**Can you interpret the odds ratios?**

You can interpret the odds ratios in two ways:

**Way one:**

<span style="color:purple">Individuals who had a pre-existing health condition had higher odds of having more severe disease (e.g. “severe” disease vs “mild” or “moderate” disease) relative to individuals who did not have a pre-existing health condition (odds ratio = 2.31, 95% confidence interval = 1.45-4.56), when holding other variables constant</span>

<span style="color:purple">Individuals who smoked had higher odds of having more severe disease (e.g. “severe” disease vs “mild” or “moderate” disease) relative to individuals who did not smoke (odds ratio = 1.45, 95% confidence interval = 0.89-4.56) when holding other variables constant</span>

<span style="color:purple">A one unit increase in the number of alcohol units consumed weekly increased the odds of having more severe disease (e.g. “severe” disease vs “mild” or “moderate” disease), when holding the other variables constant (odds ratio = 1.12, 95% confidence interval = 1.02-1.45)</span>

**Way two:**

<span style="color:purple">Individuals who had a pre-existing health condition had 2.31x higher odds of having more severe disease (e.g. “severe” disease vs “mild” or “moderate” disease) relative to individuals who did not have a pre-existing health condition (95% confidence interval = 1.45-4.56), when holding other variables constant</span>

<span style="color:purple">Individuals who smoked had 1.45x higher odds of having more severe disease (e.g. “severe” disease vs “mild” or “moderate” disease) relative to individuals who did not smoke (95% confidence interval = 0.89-4.56) when holding other variables constant</span>

<span style="color:purple">A one unit increase in the number of alcohol units consumed weekly increased the odds of having more severe disease (e.g. “severe” disease vs “mild” or “moderate” disease) by 1.12, when holding the other variables constant (95% confidence interval = 1.02-1.45)</span>

**Which rows would be significant if you looked at the p-values and why?**

<span style="color:purple">*	Pre-existing_healthYes </span>
<span style="color:purple">*	Num_alcohol_units</span>

<span style="color:purple">The 95% confidence interval around the odds ratio does not cross 1 for these comparisons (i.e. both the upper and the lower bound are higher than 1 OR both the upper and the lower bound are lower than 1). For SmokesYes, the 95% confidence interval crosses 1 (i.e. the lower confidence interval bound is below 1 and the higher confidence interval bound is above 1). This means when we look at the output, the p-value for SmokesYes will be above 0.05 (i.e. not significant).</span>

<!--chapter:end:05-Extending-binary-logistic-regression.Rmd-->

